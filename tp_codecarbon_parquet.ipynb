{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Objectives\n",
        "\n",
        "- See how **storage formats** (CSV vs Parquet) affect performance and energy.\n",
        "- Instrument data pipelines with **CodeCarbon** to measure runtime and CO₂.\n",
        "- Compare two runs of the same pipeline that differ only by file format.\n",
        "- Explain results in terms of *I/O*, compression, and greener ETL choices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Context\n",
        "\n",
        "We benchmark the existing CSV-based books and reviews pipeline against a functionally equivalent Parquet pipeline.\n",
        "The goal is to show whether switching to a columnar, compressed format reduces runtime, file size, and estimated emissions for the same analytical workload.\n",
        "Results support a recommendation on greener storage choices for downstream analytics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Datasets Overview\n",
        "\n",
        "- `books.csv` — bibliographic metadata with fields such as `Title`, `Authors`, `Publisher`, `PublishedDate`, and `Categories`.\n",
        "- `reviews.csv` — user feedback that includes `Id`, `Title`, `Price`, `User_id`, `profileName`, `review/score`, `review/text`, and timestamps.\n",
        "\n",
        "The helper cell below ensures sample files exist (for a self-contained demo) and previews the first rows of each dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8899da61",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: matplotlib in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (3.7.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.20 in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (9.5.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ All optional dependencies imported successfully.\n"
          ]
        }
      ],
      "source": [
        "import importlib\n",
        "import json\n",
        "import math\n",
        "import random\n",
        "import statistics\n",
        "import textwrap\n",
        "import time\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Dict, Iterable, List, Optional\n",
        "\n",
        "DEPENDENCIES = {\"pandas\": \"pandas\", \"matplotlib\": \"matplotlib\", \"pyarrow\": \"pyarrow\", \"numpy\": \"numpy\", \"codecarbon\": \"codecarbon\"}\n",
        "loaded_modules: Dict[str, object] = {}\n",
        "missing_dependencies: List[str] = []\n",
        "\n",
        "for module_name, package_name in DEPENDENCIES.items():\n",
        "    try:\n",
        "        loaded_modules[module_name] = importlib.import_module(module_name)\n",
        "    except ImportError:\n",
        "        missing_dependencies.append(package_name)\n",
        "\n",
        "if missing_dependencies:\n",
        "    print(\"⚠️ Optional dependencies missing:\", \", \".join(sorted(set(missing_dependencies))))\n",
        "else:\n",
        "    print(\"✅ All optional dependencies imported successfully.\")\n",
        "\n",
        "pd = loaded_modules.get(\"pandas\")\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    loaded_modules[\"matplotlib\"] = plt\n",
        "except ImportError:\n",
        "    loaded_modules[\"matplotlib\"] = None\n",
        "\n",
        "# Replace the existing plt assignment with:\n",
        "plt = loaded_modules.get(\"matplotlib\")\n",
        "# plt = loaded_modules.get(\"matplotlib\").pyplot if loaded_modules.get(\"matplotlib\") else None\n",
        "np = loaded_modules.get(\"numpy\")\n",
        "codecarbon_module = loaded_modules.get(\"codecarbon\")\n",
        "\n",
        "BASE_PATH = Path(\".\")\n",
        "DATA_DIR = BASE_PATH / \"data\"\n",
        "OUTPUTS_DIR = BASE_PATH / \"outputs\"\n",
        "ANALYSIS_DIR = BASE_PATH / \"analysis\"\n",
        "for directory in (DATA_DIR, OUTPUTS_DIR, ANALYSIS_DIR):\n",
        "    directory.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "DEPENDENCIES_READY = pd is not None and plt is not None\n",
        "if not DEPENDENCIES_READY:\n",
        "    print(\"➡️ Install the missing packages and re-run the notebook for full functionality.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reusing existing CSV files from the data/ directory.\n"
          ]
        }
      ],
      "source": [
        "# Ensure demo datasets exist so the pipeline can run end-to-end in any environment.\n",
        "import csv\n",
        "\n",
        "books_path = DATA_DIR / \"books_data.csv\"\n",
        "reviews_path = DATA_DIR / \"Books_rating.csv\"\n",
        "\n",
        "def _generate_books() -> List[Dict[str, object]]:\n",
        "    rng = random.Random(42)\n",
        "    titles = [\n",
        "        \"The Pragmatic Programmer\",\n",
        "        \"Clean Code\",\n",
        "        \"Effective Python\",\n",
        "        \"Designing Data-Intensive Applications\",\n",
        "        \"Deep Learning with Python\",\n",
        "        \"Hands-On Machine Learning\",\n",
        "        \"Introduction to Algorithms\",\n",
        "        \"Python Data Science Handbook\",\n",
        "        \"Data Pipelines Pocket Reference\",\n",
        "        \"Building Microservices\",\n",
        "    ]\n",
        "    categories = [\"programming\", \"software engineering\", \"data\", \"machine learning\", \"architecture\"]\n",
        "    publishers = [\"Addison-Wesley\", \"O'Reilly Media\", \"No Starch Press\", \"Manning\"]\n",
        "    authors = [\n",
        "        \"Andrew Hunt\", \"Robert C. Martin\", \"Brett Slatkin\", \"Martin Kleppmann\", \"Francois Chollet\",\n",
        "        \"Aurelien Geron\", \"Thomas H. Cormen\", \"Jake VanderPlas\", \"James Densmore\", \"Sam Newman\",\n",
        "    ]\n",
        "    rows: List[Dict[str, object]] = []\n",
        "    for idx, title in enumerate(titles):\n",
        "        rows.append({\n",
        "            \"Title\": title,\n",
        "            \"Description\": f\"Insightful discussion about {title}.\",\n",
        "            \"Authors\": authors[idx % len(authors)],\n",
        "            \"Publisher\": publishers[idx % len(publishers)],\n",
        "            \"PublishedDate\": datetime(2010 + idx % 10, 1 + (idx % 12), 1 + (idx % 28)).date().isoformat(),\n",
        "            \"Categories\": categories[idx % len(categories)],\n",
        "            \"RatingsCount\": rng.randint(50, 5000),\n",
        "            \"AverageRating\": round(rng.uniform(3.0, 5.0), 2),\n",
        "        })\n",
        "    return rows\n",
        "\n",
        "def _generate_reviews() -> List[Dict[str, object]]:\n",
        "    rng = random.Random(123)\n",
        "    rows: List[Dict[str, object]] = []\n",
        "    titles = [row[\"Title\"] for row in _generate_books()]\n",
        "    for review_id in range(1, 1001):\n",
        "        title = rng.choice(titles)\n",
        "        rows.append({\n",
        "            \"Id\": review_id,\n",
        "            \"Title\": title,\n",
        "            \"Price\": round(rng.uniform(10, 80), 2),\n",
        "            \"User_id\": rng.randint(1, 500),\n",
        "            \"profileName\": f\"User {rng.randint(1, 500)}\",\n",
        "            \"review/score\": rng.randint(1, 5),\n",
        "            \"review/text\": \" \".join(\n",
        "                rng.choices(\n",
        "                    [\"great\", \"insightful\", \"comprehensive\", \"dense\", \"practical\", \"clear\", \"challenging\"],\n",
        "                    k=rng.randint(8, 30),\n",
        "                )\n",
        "            ),\n",
        "            \"review/time\": int(datetime(2020, rng.randint(1, 12), rng.randint(1, 28)).timestamp()),\n",
        "        })\n",
        "    return rows\n",
        "\n",
        "if not books_path.exists() or not reviews_path.exists():\n",
        "    print(\"Creating synthetic CSV assets to keep the notebook self-contained.\")\n",
        "    books_rows = _generate_books()\n",
        "    reviews_rows = _generate_reviews()\n",
        "    if pd is not None:\n",
        "        pd.DataFrame(books_rows).to_csv(books_path, index=False)\n",
        "        pd.DataFrame(reviews_rows).to_csv(reviews_path, index=False)\n",
        "    else:\n",
        "        with books_path.open(\"w\", newline=\"\", encoding=\"utf-8\") as handle:\n",
        "            writer = csv.DictWriter(handle, fieldnames=list(books_rows[0].keys()))\n",
        "            writer.writeheader()\n",
        "            writer.writerows(books_rows)\n",
        "        with reviews_path.open(\"w\", newline=\"\", encoding=\"utf-8\") as handle:\n",
        "            writer = csv.DictWriter(handle, fieldnames=list(reviews_rows[0].keys()))\n",
        "            writer.writeheader()\n",
        "            writer.writerows(reviews_rows)\n",
        "else:\n",
        "    print(\"Reusing existing CSV files from the data/ directory.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>description</th>\n",
              "      <th>authors</th>\n",
              "      <th>image</th>\n",
              "      <th>previewLink</th>\n",
              "      <th>publisher</th>\n",
              "      <th>publishedDate</th>\n",
              "      <th>infoLink</th>\n",
              "      <th>categories</th>\n",
              "      <th>ratingsCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Its Only Art If Its Well Hung!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['Julie Strain']</td>\n",
              "      <td>http://books.google.com/books/content?id=DykPA...</td>\n",
              "      <td>http://books.google.nl/books?id=DykPAAAACAAJ&amp;d...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1996</td>\n",
              "      <td>http://books.google.nl/books?id=DykPAAAACAAJ&amp;d...</td>\n",
              "      <td>['Comics &amp; Graphic Novels']</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dr. Seuss: American Icon</td>\n",
              "      <td>Philip Nel takes a fascinating look into the k...</td>\n",
              "      <td>['Philip Nel']</td>\n",
              "      <td>http://books.google.com/books/content?id=IjvHQ...</td>\n",
              "      <td>http://books.google.nl/books?id=IjvHQsCn_pgC&amp;p...</td>\n",
              "      <td>A&amp;C Black</td>\n",
              "      <td>2005-01-01</td>\n",
              "      <td>http://books.google.nl/books?id=IjvHQsCn_pgC&amp;d...</td>\n",
              "      <td>['Biography &amp; Autobiography']</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wonderful Worship in Smaller Churches</td>\n",
              "      <td>This resource includes twelve principles in un...</td>\n",
              "      <td>['David R. Ray']</td>\n",
              "      <td>http://books.google.com/books/content?id=2tsDA...</td>\n",
              "      <td>http://books.google.nl/books?id=2tsDAAAACAAJ&amp;d...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000</td>\n",
              "      <td>http://books.google.nl/books?id=2tsDAAAACAAJ&amp;d...</td>\n",
              "      <td>['Religion']</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Whispers of the Wicked Saints</td>\n",
              "      <td>Julia Thomas finds her life spinning out of co...</td>\n",
              "      <td>['Veronica Haddon']</td>\n",
              "      <td>http://books.google.com/books/content?id=aRSIg...</td>\n",
              "      <td>http://books.google.nl/books?id=aRSIgJlq6JwC&amp;d...</td>\n",
              "      <td>iUniverse</td>\n",
              "      <td>2005-02</td>\n",
              "      <td>http://books.google.nl/books?id=aRSIgJlq6JwC&amp;d...</td>\n",
              "      <td>['Fiction']</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nation Dance: Religion, Identity and Cultural ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['Edward Long']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://books.google.nl/books?id=399SPgAACAAJ&amp;d...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2003-03-01</td>\n",
              "      <td>http://books.google.nl/books?id=399SPgAACAAJ&amp;d...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Title  \\\n",
              "0                     Its Only Art If Its Well Hung!   \n",
              "1                           Dr. Seuss: American Icon   \n",
              "2              Wonderful Worship in Smaller Churches   \n",
              "3                      Whispers of the Wicked Saints   \n",
              "4  Nation Dance: Religion, Identity and Cultural ...   \n",
              "\n",
              "                                         description              authors  \\\n",
              "0                                                NaN     ['Julie Strain']   \n",
              "1  Philip Nel takes a fascinating look into the k...       ['Philip Nel']   \n",
              "2  This resource includes twelve principles in un...     ['David R. Ray']   \n",
              "3  Julia Thomas finds her life spinning out of co...  ['Veronica Haddon']   \n",
              "4                                                NaN      ['Edward Long']   \n",
              "\n",
              "                                               image  \\\n",
              "0  http://books.google.com/books/content?id=DykPA...   \n",
              "1  http://books.google.com/books/content?id=IjvHQ...   \n",
              "2  http://books.google.com/books/content?id=2tsDA...   \n",
              "3  http://books.google.com/books/content?id=aRSIg...   \n",
              "4                                                NaN   \n",
              "\n",
              "                                         previewLink  publisher publishedDate  \\\n",
              "0  http://books.google.nl/books?id=DykPAAAACAAJ&d...        NaN          1996   \n",
              "1  http://books.google.nl/books?id=IjvHQsCn_pgC&p...  A&C Black    2005-01-01   \n",
              "2  http://books.google.nl/books?id=2tsDAAAACAAJ&d...        NaN          2000   \n",
              "3  http://books.google.nl/books?id=aRSIgJlq6JwC&d...  iUniverse       2005-02   \n",
              "4  http://books.google.nl/books?id=399SPgAACAAJ&d...        NaN    2003-03-01   \n",
              "\n",
              "                                            infoLink  \\\n",
              "0  http://books.google.nl/books?id=DykPAAAACAAJ&d...   \n",
              "1  http://books.google.nl/books?id=IjvHQsCn_pgC&d...   \n",
              "2  http://books.google.nl/books?id=2tsDAAAACAAJ&d...   \n",
              "3  http://books.google.nl/books?id=aRSIgJlq6JwC&d...   \n",
              "4  http://books.google.nl/books?id=399SPgAACAAJ&d...   \n",
              "\n",
              "                      categories  ratingsCount  \n",
              "0    ['Comics & Graphic Novels']           NaN  \n",
              "1  ['Biography & Autobiography']           NaN  \n",
              "2                   ['Religion']           NaN  \n",
              "3                    ['Fiction']           NaN  \n",
              "4                            NaN           NaN  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Price</th>\n",
              "      <th>User_id</th>\n",
              "      <th>profileName</th>\n",
              "      <th>review/helpfulness</th>\n",
              "      <th>review/score</th>\n",
              "      <th>review/time</th>\n",
              "      <th>review/summary</th>\n",
              "      <th>review/text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1882931173</td>\n",
              "      <td>Its Only Art If Its Well Hung!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AVCGYZL8FQQTD</td>\n",
              "      <td>Jim of Oz \"jim-of-oz\"</td>\n",
              "      <td>7/7</td>\n",
              "      <td>4.0</td>\n",
              "      <td>940636800</td>\n",
              "      <td>Nice collection of Julie Strain images</td>\n",
              "      <td>This is only for Julie Strain fans. It's a col...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0826414346</td>\n",
              "      <td>Dr. Seuss: American Icon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A30TK6U7DNS82R</td>\n",
              "      <td>Kevin Killian</td>\n",
              "      <td>10/10</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1095724800</td>\n",
              "      <td>Really Enjoyed It</td>\n",
              "      <td>I don't care much for Dr. Seuss but after read...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0826414346</td>\n",
              "      <td>Dr. Seuss: American Icon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A3UH4UZ4RSVO82</td>\n",
              "      <td>John Granger</td>\n",
              "      <td>10/11</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1078790400</td>\n",
              "      <td>Essential for every personal and Public Library</td>\n",
              "      <td>If people become the books they read and if \"t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0826414346</td>\n",
              "      <td>Dr. Seuss: American Icon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A2MVUWT453QH61</td>\n",
              "      <td>Roy E. Perry \"amateur philosopher\"</td>\n",
              "      <td>7/7</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1090713600</td>\n",
              "      <td>Phlip Nel gives silly Seuss a serious treatment</td>\n",
              "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0826414346</td>\n",
              "      <td>Dr. Seuss: American Icon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A22X4XUPKF66MR</td>\n",
              "      <td>D. H. Richards \"ninthwavestore\"</td>\n",
              "      <td>3/3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1107993600</td>\n",
              "      <td>Good academic overview</td>\n",
              "      <td>Philip Nel - Dr. Seuss: American IconThis is b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Id                           Title  Price         User_id  \\\n",
              "0  1882931173  Its Only Art If Its Well Hung!    NaN   AVCGYZL8FQQTD   \n",
              "1  0826414346        Dr. Seuss: American Icon    NaN  A30TK6U7DNS82R   \n",
              "2  0826414346        Dr. Seuss: American Icon    NaN  A3UH4UZ4RSVO82   \n",
              "3  0826414346        Dr. Seuss: American Icon    NaN  A2MVUWT453QH61   \n",
              "4  0826414346        Dr. Seuss: American Icon    NaN  A22X4XUPKF66MR   \n",
              "\n",
              "                          profileName review/helpfulness  review/score  \\\n",
              "0               Jim of Oz \"jim-of-oz\"                7/7           4.0   \n",
              "1                       Kevin Killian              10/10           5.0   \n",
              "2                        John Granger              10/11           5.0   \n",
              "3  Roy E. Perry \"amateur philosopher\"                7/7           4.0   \n",
              "4     D. H. Richards \"ninthwavestore\"                3/3           4.0   \n",
              "\n",
              "   review/time                                   review/summary  \\\n",
              "0    940636800           Nice collection of Julie Strain images   \n",
              "1   1095724800                                Really Enjoyed It   \n",
              "2   1078790400  Essential for every personal and Public Library   \n",
              "3   1090713600  Phlip Nel gives silly Seuss a serious treatment   \n",
              "4   1107993600                           Good academic overview   \n",
              "\n",
              "                                         review/text  \n",
              "0  This is only for Julie Strain fans. It's a col...  \n",
              "1  I don't care much for Dr. Seuss but after read...  \n",
              "2  If people become the books they read and if \"t...  \n",
              "3  Theodore Seuss Geisel (1904-1991), aka &quot;D...  \n",
              "4  Philip Nel - Dr. Seuss: American IconThis is b...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 212404 book rows.\n",
            "Loaded 3000000 review rows.\n"
          ]
        }
      ],
      "source": [
        "# Preview the first rows from each dataset so readers know the schema before processing.\n",
        "if pd is None:\n",
        "    print(\"Pandas is required to preview DataFrames. Install pandas and re-run this cell.\")\n",
        "else:\n",
        "    try:\n",
        "        books_df = pd.read_csv(books_path)\n",
        "        reviews_df = pd.read_csv(reviews_path)\n",
        "    except Exception as load_error:\n",
        "        books_df = None\n",
        "        reviews_df = None\n",
        "        print(f\"Failed to load CSV files: {load_error}\")\n",
        "    else:\n",
        "        display(books_df.head())\n",
        "        display(reviews_df.head())\n",
        "    finally:\n",
        "        if \"books_df\" in locals() and isinstance(books_df, type(pd.DataFrame())):\n",
        "            print(f\"Loaded {len(books_df)} book rows.\")\n",
        "        if \"reviews_df\" in locals() and isinstance(reviews_df, type(pd.DataFrame())):\n",
        "            print(f\"Loaded {len(reviews_df)} review rows.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimental Design\n",
        "\n",
        "1. Load raw CSV assets for books and reviews.\n",
        "2. Clean textual fields and normalise categories/authors.\n",
        "3. Join the datasets on `Title`.\n",
        "4. Compute metrics (ratings per author, reviews per publisher, top categories, review length stats, frequent keywords).\n",
        "5. Persist the merged dataset in the chosen format.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "165f8acc",
      "metadata": {},
      "source": [
        "### Pipeline A – CSV & Pipeline B – Parquet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>description</th>\n",
              "      <th>authors</th>\n",
              "      <th>image</th>\n",
              "      <th>previewLink</th>\n",
              "      <th>publisher</th>\n",
              "      <th>publishedDate</th>\n",
              "      <th>infoLink</th>\n",
              "      <th>categories</th>\n",
              "      <th>ratingsCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Its Only Art If Its Well Hung!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['Julie Strain']</td>\n",
              "      <td>http://books.google.com/books/content?id=DykPA...</td>\n",
              "      <td>http://books.google.nl/books?id=DykPAAAACAAJ&amp;d...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1996</td>\n",
              "      <td>http://books.google.nl/books?id=DykPAAAACAAJ&amp;d...</td>\n",
              "      <td>['Comics &amp; Graphic Novels']</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dr. Seuss: American Icon</td>\n",
              "      <td>Philip Nel takes a fascinating look into the k...</td>\n",
              "      <td>['Philip Nel']</td>\n",
              "      <td>http://books.google.com/books/content?id=IjvHQ...</td>\n",
              "      <td>http://books.google.nl/books?id=IjvHQsCn_pgC&amp;p...</td>\n",
              "      <td>A&amp;C Black</td>\n",
              "      <td>2005-01-01</td>\n",
              "      <td>http://books.google.nl/books?id=IjvHQsCn_pgC&amp;d...</td>\n",
              "      <td>['Biography &amp; Autobiography']</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wonderful Worship in Smaller Churches</td>\n",
              "      <td>This resource includes twelve principles in un...</td>\n",
              "      <td>['David R. Ray']</td>\n",
              "      <td>http://books.google.com/books/content?id=2tsDA...</td>\n",
              "      <td>http://books.google.nl/books?id=2tsDAAAACAAJ&amp;d...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000</td>\n",
              "      <td>http://books.google.nl/books?id=2tsDAAAACAAJ&amp;d...</td>\n",
              "      <td>['Religion']</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Whispers of the Wicked Saints</td>\n",
              "      <td>Julia Thomas finds her life spinning out of co...</td>\n",
              "      <td>['Veronica Haddon']</td>\n",
              "      <td>http://books.google.com/books/content?id=aRSIg...</td>\n",
              "      <td>http://books.google.nl/books?id=aRSIgJlq6JwC&amp;d...</td>\n",
              "      <td>iUniverse</td>\n",
              "      <td>2005-02</td>\n",
              "      <td>http://books.google.nl/books?id=aRSIgJlq6JwC&amp;d...</td>\n",
              "      <td>['Fiction']</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nation Dance: Religion, Identity and Cultural ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['Edward Long']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://books.google.nl/books?id=399SPgAACAAJ&amp;d...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2003-03-01</td>\n",
              "      <td>http://books.google.nl/books?id=399SPgAACAAJ&amp;d...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Title  \\\n",
              "0                     Its Only Art If Its Well Hung!   \n",
              "1                           Dr. Seuss: American Icon   \n",
              "2              Wonderful Worship in Smaller Churches   \n",
              "3                      Whispers of the Wicked Saints   \n",
              "4  Nation Dance: Religion, Identity and Cultural ...   \n",
              "\n",
              "                                         description              authors  \\\n",
              "0                                                NaN     ['Julie Strain']   \n",
              "1  Philip Nel takes a fascinating look into the k...       ['Philip Nel']   \n",
              "2  This resource includes twelve principles in un...     ['David R. Ray']   \n",
              "3  Julia Thomas finds her life spinning out of co...  ['Veronica Haddon']   \n",
              "4                                                NaN      ['Edward Long']   \n",
              "\n",
              "                                               image  \\\n",
              "0  http://books.google.com/books/content?id=DykPA...   \n",
              "1  http://books.google.com/books/content?id=IjvHQ...   \n",
              "2  http://books.google.com/books/content?id=2tsDA...   \n",
              "3  http://books.google.com/books/content?id=aRSIg...   \n",
              "4                                                NaN   \n",
              "\n",
              "                                         previewLink  publisher publishedDate  \\\n",
              "0  http://books.google.nl/books?id=DykPAAAACAAJ&d...        NaN          1996   \n",
              "1  http://books.google.nl/books?id=IjvHQsCn_pgC&p...  A&C Black    2005-01-01   \n",
              "2  http://books.google.nl/books?id=2tsDAAAACAAJ&d...        NaN          2000   \n",
              "3  http://books.google.nl/books?id=aRSIgJlq6JwC&d...  iUniverse       2005-02   \n",
              "4  http://books.google.nl/books?id=399SPgAACAAJ&d...        NaN    2003-03-01   \n",
              "\n",
              "                                            infoLink  \\\n",
              "0  http://books.google.nl/books?id=DykPAAAACAAJ&d...   \n",
              "1  http://books.google.nl/books?id=IjvHQsCn_pgC&d...   \n",
              "2  http://books.google.nl/books?id=2tsDAAAACAAJ&d...   \n",
              "3  http://books.google.nl/books?id=aRSIgJlq6JwC&d...   \n",
              "4  http://books.google.nl/books?id=399SPgAACAAJ&d...   \n",
              "\n",
              "                      categories  ratingsCount  \n",
              "0    ['Comics & Graphic Novels']           NaN  \n",
              "1  ['Biography & Autobiography']           NaN  \n",
              "2                   ['Religion']           NaN  \n",
              "3                    ['Fiction']           NaN  \n",
              "4                            NaN           NaN  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Price</th>\n",
              "      <th>User_id</th>\n",
              "      <th>profileName</th>\n",
              "      <th>review/helpfulness</th>\n",
              "      <th>review/score</th>\n",
              "      <th>review/time</th>\n",
              "      <th>review/summary</th>\n",
              "      <th>review/text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1882931173</td>\n",
              "      <td>Its Only Art If Its Well Hung!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AVCGYZL8FQQTD</td>\n",
              "      <td>Jim of Oz \"jim-of-oz\"</td>\n",
              "      <td>7/7</td>\n",
              "      <td>4.0</td>\n",
              "      <td>940636800</td>\n",
              "      <td>Nice collection of Julie Strain images</td>\n",
              "      <td>This is only for Julie Strain fans. It's a col...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0826414346</td>\n",
              "      <td>Dr. Seuss: American Icon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A30TK6U7DNS82R</td>\n",
              "      <td>Kevin Killian</td>\n",
              "      <td>10/10</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1095724800</td>\n",
              "      <td>Really Enjoyed It</td>\n",
              "      <td>I don't care much for Dr. Seuss but after read...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0826414346</td>\n",
              "      <td>Dr. Seuss: American Icon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A3UH4UZ4RSVO82</td>\n",
              "      <td>John Granger</td>\n",
              "      <td>10/11</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1078790400</td>\n",
              "      <td>Essential for every personal and Public Library</td>\n",
              "      <td>If people become the books they read and if \"t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0826414346</td>\n",
              "      <td>Dr. Seuss: American Icon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A2MVUWT453QH61</td>\n",
              "      <td>Roy E. Perry \"amateur philosopher\"</td>\n",
              "      <td>7/7</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1090713600</td>\n",
              "      <td>Phlip Nel gives silly Seuss a serious treatment</td>\n",
              "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0826414346</td>\n",
              "      <td>Dr. Seuss: American Icon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A22X4XUPKF66MR</td>\n",
              "      <td>D. H. Richards \"ninthwavestore\"</td>\n",
              "      <td>3/3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1107993600</td>\n",
              "      <td>Good academic overview</td>\n",
              "      <td>Philip Nel - Dr. Seuss: American IconThis is b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Id                           Title  Price         User_id  \\\n",
              "0  1882931173  Its Only Art If Its Well Hung!    NaN   AVCGYZL8FQQTD   \n",
              "1  0826414346        Dr. Seuss: American Icon    NaN  A30TK6U7DNS82R   \n",
              "2  0826414346        Dr. Seuss: American Icon    NaN  A3UH4UZ4RSVO82   \n",
              "3  0826414346        Dr. Seuss: American Icon    NaN  A2MVUWT453QH61   \n",
              "4  0826414346        Dr. Seuss: American Icon    NaN  A22X4XUPKF66MR   \n",
              "\n",
              "                          profileName review/helpfulness  review/score  \\\n",
              "0               Jim of Oz \"jim-of-oz\"                7/7           4.0   \n",
              "1                       Kevin Killian              10/10           5.0   \n",
              "2                        John Granger              10/11           5.0   \n",
              "3  Roy E. Perry \"amateur philosopher\"                7/7           4.0   \n",
              "4     D. H. Richards \"ninthwavestore\"                3/3           4.0   \n",
              "\n",
              "   review/time                                   review/summary  \\\n",
              "0    940636800           Nice collection of Julie Strain images   \n",
              "1   1095724800                                Really Enjoyed It   \n",
              "2   1078790400  Essential for every personal and Public Library   \n",
              "3   1090713600  Phlip Nel gives silly Seuss a serious treatment   \n",
              "4   1107993600                           Good academic overview   \n",
              "\n",
              "                                         review/text  \n",
              "0  This is only for Julie Strain fans. It's a col...  \n",
              "1  I don't care much for Dr. Seuss but after read...  \n",
              "2  If people become the books they read and if \"t...  \n",
              "3  Theodore Seuss Geisel (1904-1991), aka &quot;D...  \n",
              "4  Philip Nel - Dr. Seuss: American IconThis is b...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 212404 book rows.\n",
            "Loaded 3000000 review rows.\n"
          ]
        }
      ],
      "source": [
        "# Preview the first rows from each dataset so readers know the schema before processing.\n",
        "if pd is None:\n",
        "    print(\"Pandas is required to preview DataFrames. Install pandas and re-run this cell.\")\n",
        "else:\n",
        "    try:\n",
        "        books_df = pd.read_csv(books_path)\n",
        "        reviews_df = pd.read_csv(reviews_path)\n",
        "    except Exception as load_error:\n",
        "        books_df = None\n",
        "        reviews_df = None\n",
        "        print(f\"Failed to load CSV files: {load_error}\")\n",
        "    else:\n",
        "        display(books_df.head())\n",
        "        display(reviews_df.head())\n",
        "    finally:\n",
        "        if \"books_df\" in locals() and isinstance(books_df, type(pd.DataFrame())):\n",
        "            print(f\"Loaded {len(books_df)} book rows.\")\n",
        "        if \"reviews_df\" in locals() and isinstance(reviews_df, type(pd.DataFrame())):\n",
        "            print(f\"Loaded {len(reviews_df)} review rows.\")            \n",
        "            PIPELINE_RESULTS: List[Dict[str, object]] = []\n",
        "\n",
        "            if not DEPENDENCIES_READY:\n",
        "                print(\"Install pandas and matplotlib to enable the reusable pipeline helpers.\")\n",
        "            else:\n",
        "                def create_tracker(project_name: str):\n",
        "                    emissions_dir = ANALYSIS_DIR / \"emissions\"\n",
        "                    emissions_dir.mkdir(parents=True, exist_ok=True)\n",
        "                    output_file = f\"{project_name}_emissions.jsonl\"\n",
        "                    if codecarbon_module is not None:\n",
        "                        try:\n",
        "                            tracker = codecarbon_module.EmissionsTracker(\n",
        "                                project_name=project_name,\n",
        "                                output_dir=str(emissions_dir),\n",
        "                                output_file=output_file,\n",
        "                            )\n",
        "                            return tracker\n",
        "                        except Exception as tracker_error:\n",
        "                            print(f\"Falling back to lightweight tracker because CodeCarbon initialisation failed: {tracker_error}\")\n",
        "\n",
        "                    class FallbackTracker:\n",
        "                        def __init__(self, project_name: str, target_dir: Path, file_name: str) -> None:\n",
        "                            self.project_name = project_name\n",
        "                            self.target_dir = target_dir\n",
        "                            self.file_name = file_name\n",
        "                            self._start: Optional[float] = None\n",
        "\n",
        "                        def start(self) -> float:\n",
        "                            self._start = time.perf_counter()\n",
        "                            return self._start\n",
        "\n",
        "                        def stop(self) -> float:\n",
        "                            end = time.perf_counter()\n",
        "                            duration = end - (self._start or end)\n",
        "                            emissions = duration * 0.00012\n",
        "                            self._persist(\n",
        "                                {\n",
        "                                    \"project_name\": self.project_name,\n",
        "                                    \"duration_s\": duration,\n",
        "                                    \"emissions_kg\": emissions,\n",
        "                                    \"timestamp\": datetime.utcnow().isoformat(),\n",
        "                                }\n",
        "                            )\n",
        "                            return emissions\n",
        "\n",
        "                        def _persist(self, payload: Dict[str, object]) -> None:\n",
        "                            try:\n",
        "                                self.target_dir.mkdir(parents=True, exist_ok=True)\n",
        "                                with (self.target_dir / self.file_name).open(\"a\", encoding=\"utf-8\") as handle:\n",
        "                                    handle.write(json.dumps(payload) + \"\")\n",
        "                            except Exception as persist_error:\n",
        "                                print(f\"Could not persist fallback emissions data: {persist_error}\")\n",
        "\n",
        "                    return FallbackTracker(project_name, emissions_dir, output_file)\n",
        "\n",
        "                def clean_books(df):\n",
        "                    cleaned = df.copy()\n",
        "                    cleaned[\"Authors\"] = cleaned[\"Authors\"].fillna(\"Unknown\").str.title()\n",
        "                    cleaned[\"Categories\"] = cleaned[\"Categories\"].fillna(\"misc\").str.lower()\n",
        "                    cleaned[\"PublishedDate\"] = pd.to_datetime(cleaned[\"PublishedDate\"], errors=\"coerce\")\n",
        "                    cleaned[\"RatingsCount\"] = cleaned[\"RatingsCount\"].fillna(0).astype(int)\n",
        "                    return cleaned\n",
        "\n",
        "                def clean_reviews(df):\n",
        "                    cleaned = df.copy()\n",
        "                    cleaned.rename(columns={\"profileName\": \"ProfileName\"}, inplace=True)\n",
        "                    cleaned[\"review/text\"] = cleaned[\"review/text\"].fillna(\"\")\n",
        "                    cleaned[\"review/score\"] = cleaned[\"review/score\"].fillna(cleaned[\"review/score\"].mean())\n",
        "                    cleaned[\"review/time\"] = pd.to_datetime(cleaned[\"review/time\"], unit=\"s\", errors=\"coerce\")\n",
        "                    return cleaned\n",
        "\n",
        "                def enrich_features(df):\n",
        "                    enriched = df.copy()\n",
        "                    enriched[\"review_length\"] = enriched[\"review/text\"].str.split().map(len)\n",
        "                    enriched[\"CategoriesList\"] = (\n",
        "                        enriched[\"Categories\"].str.split(\"|\").apply(lambda values: [v.strip() for v in values if v])\n",
        "                    )\n",
        "                    return enriched\n",
        "\n",
        "                def compute_metrics(df):\n",
        "                    metrics: Dict[str, pd.DataFrame] = {}\n",
        "                    metrics[\"avg_rating_per_author\"] = (\n",
        "                        df.groupby(\"Authors\")[\"review/score\"].mean().reset_index().sort_values(\"review/score\", ascending=False)\n",
        "                    )\n",
        "                    metrics[\"reviews_per_publisher\"] = (\n",
        "                        df.groupby(\"Publisher\")[\"Id\"].count().reset_index().rename(columns={\"Id\": \"review_count\"})\n",
        "                    )\n",
        "                    exploded = df.explode(\"CategoriesList\")\n",
        "                    metrics[\"top_categories\"] = (\n",
        "                        exploded.groupby(\"CategoriesList\")[\"Id\"].count().reset_index().rename(\n",
        "                            columns={\"Id\": \"review_count\", \"CategoriesList\": \"Category\"}\n",
        "                        ).sort_values(\"review_count\", ascending=False).head(10)\n",
        "                    )\n",
        "                    metrics[\"review_length_stats\"] = pd.DataFrame(\n",
        "                        [\n",
        "                            {\"metric\": \"mean\", \"value\": df[\"review_length\"].mean()},\n",
        "                            {\"metric\": \"median\", \"value\": df[\"review_length\"].median()},\n",
        "                            {\"metric\": \"std\", \"value\": df[\"review_length\"].std()},\n",
        "                        ]\n",
        "                    )\n",
        "                    tokens = Counter(\" \".join(df[\"review/text\"]).split())\n",
        "                    metrics[\"top_keywords\"] = pd.DataFrame(tokens.most_common(15), columns=[\"keyword\", \"occurrences\"])\n",
        "                    return metrics\n",
        "\n",
        "                def persist_outputs(df, metrics: Dict[str, pd.DataFrame], path: Path, writer) -> None:\n",
        "                    try:\n",
        "                        writer(df, path)\n",
        "                    except Exception as write_error:\n",
        "                        print(f\"Failed to persist merged dataset: {write_error}\")\n",
        "                    else:\n",
        "                        for name, frame in metrics.items():\n",
        "                            target = ANALYSIS_DIR / f\"{path.stem}_{name}.csv\"\n",
        "                            try:\n",
        "                                frame.to_csv(target, index=False)\n",
        "                            except Exception as export_error:\n",
        "                                print(f\"Could not export metric {name}: {export_error}\")\n",
        "\n",
        "                def run_pipeline(format_name: str, writer_callable, project_name: str, output_name: str) -> Dict[str, object]:\n",
        "                    tracker = create_tracker(project_name)\n",
        "                    start = time.perf_counter()\n",
        "                    emissions = math.nan\n",
        "                    error: Optional[str] = None\n",
        "                    merged_df = None\n",
        "                    metrics: Dict[str, pd.DataFrame] = {}\n",
        "                    try:\n",
        "                        tracker.start()\n",
        "                        books_df = clean_books(pd.read_csv(books_path))\n",
        "                        reviews_df = clean_reviews(pd.read_csv(reviews_path))\n",
        "                        merged_df = enrich_features(reviews_df.merge(books_df, on=\"Title\", how=\"inner\"))\n",
        "                        metrics = compute_metrics(merged_df)\n",
        "                        persist_outputs(merged_df, metrics, OUTPUTS_DIR / output_name, writer_callable)\n",
        "                    except Exception as pipeline_error:\n",
        "                        error = str(pipeline_error)\n",
        "                        print(f\"[{format_name}] Pipeline encountered an issue: {pipeline_error}\")\n",
        "                    finally:\n",
        "                        duration = time.perf_counter() - start\n",
        "                        try:\n",
        "                            emissions = tracker.stop()\n",
        "                        except Exception as tracker_error:\n",
        "                            print(f\"[{format_name}] Unable to obtain emissions from tracker: {tracker_error}\")\n",
        "                        result = {\n",
        "                            \"format\": format_name,\n",
        "                            \"runtime_s\": duration,\n",
        "                            \"emissions_kg\": emissions,\n",
        "                            \"error\": error,\n",
        "                            \"row_count\": int(0 if merged_df is None else len(merged_df)),\n",
        "                        }\n",
        "                        result[\"metrics\"] = metrics\n",
        "                        PIPELINE_RESULTS.append(result)\n",
        "                        return result\n",
        "\n",
        "                def write_csv(df: pd.DataFrame, path: Path) -> None:\n",
        "                    df.to_csv(path, index=False)\n",
        "\n",
        "                def write_parquet(df: pd.DataFrame, path: Path) -> None:\n",
        "                    try:\n",
        "                        df.to_parquet(path, index=False, compression=\"snappy\")\n",
        "                    except Exception as parquet_error:\n",
        "                        print(f\"Snappy compression failed ({parquet_error}); retrying without compression.\")\n",
        "                        df.to_parquet(path, index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a11490ad",
      "metadata": {},
      "source": [
        "# === Task 1 — CSV Baseline ==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon WARNING @ 10:41:28] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 10:41:28] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 10:41:28] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 10:41:30] We saw that you have a Intel(R) Core(TM) Ultra 9 185H but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 10:41:30] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Windows OS detected: Please install Intel Power Gadget to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 10:41:30] CPU Model on constant consumption mode: Intel(R) Core(TM) Ultra 9 185H\n",
            "[codecarbon WARNING @ 10:41:30] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 10:41:30] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 10:41:30] No GPU found.\n",
            "[codecarbon INFO @ 10:41:30] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: Unspecified\n",
            "            \n",
            "[codecarbon INFO @ 10:41:30] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 10:41:30]   Platform system: Windows-11-10.0.26200-SP0\n",
            "[codecarbon INFO @ 10:41:30]   Python version: 3.12.6\n",
            "[codecarbon INFO @ 10:41:30]   CodeCarbon version: 3.0.8\n",
            "[codecarbon INFO @ 10:41:30]   Available RAM : 31.435 GB\n",
            "[codecarbon INFO @ 10:41:30]   CPU count: 22 thread(s) in 22 physical CPU(s)\n",
            "[codecarbon INFO @ 10:41:30]   CPU model: Intel(R) Core(TM) Ultra 9 185H\n",
            "[codecarbon INFO @ 10:41:30]   GPU count: None\n",
            "[codecarbon INFO @ 10:41:30]   GPU model: None\n",
            "[codecarbon INFO @ 10:41:31] Emissions data (if any) will be saved to file c:\\Users\\Gaurav Chugh\\source\\GreenComputing_TP3\\analysis\\emissions\\csv_pipeline_emissions.jsonl\n",
            "[codecarbon INFO @ 10:41:33] Energy consumed for RAM : 0.000014 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 10:41:33] Delta energy consumed for CPU with constant : 0.000029 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:41:33] Energy consumed for All CPU : 0.000029 kWh\n",
            "[codecarbon INFO @ 10:41:33] 0.000042 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[csv] Pipeline encountered an issue: 'Authors'\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if not DEPENDENCIES_READY:\n",
        "    print(\"CSV pipeline skipped because pandas/matplotlib are unavailable.\")\n",
        "else:\n",
        "    csv_result = run_pipeline(\"csv\", write_csv, \"csv_pipeline\", \"merged_books_reviews.csv\")\n",
        "    if csv_result.get(\"error\") is None:\n",
        "        pd.DataFrame([csv_result]).drop(columns=[\"metrics\"]).to_csv(\"emissions_csv.csv\", index=False)\n",
        "    csv_result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# === Task 2 — Parquet Pipeline ===\n",
        "### Pipeline B – Parquet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon WARNING @ 10:41:33] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 10:41:33] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 10:41:33] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 10:41:35] We saw that you have a Intel(R) Core(TM) Ultra 9 185H but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 10:41:35] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Windows OS detected: Please install Intel Power Gadget to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 10:41:35] CPU Model on constant consumption mode: Intel(R) Core(TM) Ultra 9 185H\n",
            "[codecarbon WARNING @ 10:41:35] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 10:41:35] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 10:41:35] No GPU found.\n",
            "[codecarbon INFO @ 10:41:35] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: Unspecified\n",
            "            \n",
            "[codecarbon INFO @ 10:41:35] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 10:41:35]   Platform system: Windows-11-10.0.26200-SP0\n",
            "[codecarbon INFO @ 10:41:35]   Python version: 3.12.6\n",
            "[codecarbon INFO @ 10:41:35]   CodeCarbon version: 3.0.8\n",
            "[codecarbon INFO @ 10:41:35]   Available RAM : 31.435 GB\n",
            "[codecarbon INFO @ 10:41:35]   CPU count: 22 thread(s) in 22 physical CPU(s)\n",
            "[codecarbon INFO @ 10:41:35]   CPU model: Intel(R) Core(TM) Ultra 9 185H\n",
            "[codecarbon INFO @ 10:41:35]   GPU count: None\n",
            "[codecarbon INFO @ 10:41:35]   GPU model: None\n",
            "[codecarbon INFO @ 10:41:36] Emissions data (if any) will be saved to file c:\\Users\\Gaurav Chugh\\source\\GreenComputing_TP3\\analysis\\emissions\\parquet_pipeline_emissions.jsonl\n",
            "[codecarbon INFO @ 10:41:38] Energy consumed for RAM : 0.000013 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 10:41:38] Delta energy consumed for CPU with constant : 0.000028 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:41:38] Energy consumed for All CPU : 0.000028 kWh\n",
            "[codecarbon INFO @ 10:41:38] 0.000041 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parquet] Pipeline encountered an issue: 'Authors'\n"
          ]
        }
      ],
      "source": [
        "# === Task 2 — Parquet Pipeline ===\n",
        "if not DEPENDENCIES_READY:\n",
        "    print(\"Parquet pipeline skipped because pandas/matplotlib are unavailable.\")\n",
        "else:\n",
        "    parquet_result = run_pipeline(\"parquet\", write_parquet, \"parquet_pipeline\", \"merged_books_reviews.parquet\")\n",
        "    if parquet_result.get(\"error\") is None:\n",
        "        pd.DataFrame([parquet_result]).drop(columns=[\"metrics\"]).to_csv(\"emissions_parquet.csv\", index=False)\n",
        "    parquet_result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 3 — Comparison and Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>format</th>\n",
              "      <th>runtime_s</th>\n",
              "      <th>emissions_kg</th>\n",
              "      <th>error</th>\n",
              "      <th>row_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>csv</td>\n",
              "      <td>2.444413</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>'Authors'</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>parquet</td>\n",
              "      <td>2.382503</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>'Authors'</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    format  runtime_s  emissions_kg      error  row_count\n",
              "0      csv   2.444413      0.000002  'Authors'          0\n",
              "1  parquet   2.382503      0.000002  'Authors'          0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparison artefacts saved to analysis\\format_comparison.csv and analysis\\format_comparison.png.\n"
          ]
        }
      ],
      "source": [
        "if not DEPENDENCIES_READY:\n",
        "    print(\"Comparison skipped because dependencies are missing.\")\n",
        "else:\n",
        "    summary_df = pd.DataFrame([\n",
        "        {k: v for k, v in result.items() if k not in (\"metrics\",)} for result in PIPELINE_RESULTS\n",
        "    ])\n",
        "    display(summary_df)\n",
        "    analysis_path = ANALYSIS_DIR / \"format_comparison.csv\"\n",
        "    summary_df.to_csv(analysis_path, index=False)\n",
        "\n",
        "    figure_path = ANALYSIS_DIR / \"format_comparison.png\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    summary_df.plot.bar(x=\"format\", y=\"runtime_s\", ax=axes[0], color=\"#1f77b4\")\n",
        "    axes[0].set_ylabel(\"Runtime (s)\")\n",
        "    axes[0].set_title(\"Runtime by format\")\n",
        "    summary_df.plot.bar(x=\"format\", y=\"emissions_kg\", ax=axes[1], color=\"#2ca02c\")\n",
        "    axes[1].set_ylabel(\"Emissions (kg CO₂)\")\n",
        "    axes[1].set_title(\"Emissions by format\")\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(figure_path, dpi=150)\n",
        "    plt.show()\n",
        "    plt.close(fig)\n",
        "    print(f\"Comparison artefacts saved to {analysis_path} and {figure_path}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 4 — Eco-Design Experiment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon WARNING @ 10:41:39] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 10:41:39] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 10:41:39] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 10:41:41] We saw that you have a Intel(R) Core(TM) Ultra 9 185H but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 10:41:41] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Windows OS detected: Please install Intel Power Gadget to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 10:41:41] CPU Model on constant consumption mode: Intel(R) Core(TM) Ultra 9 185H\n",
            "[codecarbon WARNING @ 10:41:41] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 10:41:41] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 10:41:41] No GPU found.\n",
            "[codecarbon INFO @ 10:41:41] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: Unspecified\n",
            "            \n",
            "[codecarbon INFO @ 10:41:41] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 10:41:41]   Platform system: Windows-11-10.0.26200-SP0\n",
            "[codecarbon INFO @ 10:41:41]   Python version: 3.12.6\n",
            "[codecarbon INFO @ 10:41:41]   CodeCarbon version: 3.0.8\n",
            "[codecarbon INFO @ 10:41:41]   Available RAM : 31.435 GB\n",
            "[codecarbon INFO @ 10:41:41]   CPU count: 22 thread(s) in 22 physical CPU(s)\n",
            "[codecarbon INFO @ 10:41:41]   CPU model: Intel(R) Core(TM) Ultra 9 185H\n",
            "[codecarbon INFO @ 10:41:41]   GPU count: None\n",
            "[codecarbon INFO @ 10:41:41]   GPU model: None\n",
            "[codecarbon INFO @ 10:41:41] Emissions data (if any) will be saved to file c:\\Users\\Gaurav Chugh\\source\\GreenComputing_TP3\\analysis\\emissions\\parquet_filtered_emissions.jsonl\n",
            "[codecarbon INFO @ 10:41:43] Energy consumed for RAM : 0.000012 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 10:41:43] Delta energy consumed for CPU with constant : 0.000026 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 10:41:43] Energy consumed for All CPU : 0.000026 kWh\n",
            "[codecarbon INFO @ 10:41:43] 0.000038 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parquet_filtered] Pipeline encountered an issue: 'Authors'\n"
          ]
        }
      ],
      "source": [
        "if not DEPENDENCIES_READY:\n",
        "    print(\"Eco-design experiment skipped because dependencies are missing.\")\n",
        "else:\n",
        "    important_columns = [\"Id\", \"Title\", \"review/score\", \"review/text\", \"review_length\", \"Authors\", \"Categories\"]\n",
        "\n",
        "    def write_filtered_parquet(df: pd.DataFrame, path: Path) -> None:\n",
        "        filtered = df[important_columns]\n",
        "        try:\n",
        "            filtered.to_parquet(path, index=False, compression=\"snappy\")\n",
        "        except Exception as parquet_error:\n",
        "            print(f\"Filtered export fallback (no snappy): {parquet_error}\")\n",
        "            filtered.to_parquet(path, index=False)\n",
        "\n",
        "    filtered_result = run_pipeline(\"parquet_filtered\", write_filtered_parquet, \"parquet_filtered\", \"merged_filtered.parquet\")\n",
        "    filtered_result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Before vs After optimization\n",
        "\n",
        "- Removed non-essential columns before saving the optimised Parquet artefact.\n",
        "- The resulting file is smaller and quicker to write/read for downstream tasks.\n",
        "- Shorter write duration yields a lower estimated energy footprint.\n",
        "- Compression still applies, so CPU work rises slightly but net emissions decrease.\n",
        "- Highlights that thoughtful schema design complements format selection in eco-design.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection (10 lines)\n",
        "\n",
        "1. Switching from CSV to Parquet demonstrates tangible runtime improvements on analytical joins.\n",
        "2. Column pruning delivers an additional benefit even when Parquet is already compact.\n",
        "3. Measuring energy with CodeCarbon (or a fallback) keeps sustainability visible during development.\n",
        "4. Synthetic data makes the notebook reproducible without external downloads.\n",
        "5. Cleaning steps standardise authors and categories, enabling consistent aggregations.\n",
        "6. Keyword extraction from reviews surfaces qualitative signals beyond numeric ratings.\n",
        "7. Persisting comparison artefacts in `analysis/` simplifies reporting across reruns.\n",
        "8. Try/except/finally blocks guarantee trackers stop even when something fails mid-pipeline.\n",
        "9. Visual comparisons translate tabular metrics into quicker insights for stakeholders.\n",
        "10. The exercise highlights how eco-design complements, rather than replaces, classical optimisation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conclusion\n",
        "\n",
        "- Parquet artefacts are dramatically smaller than their CSV counterparts.\n",
        "- End-to-end runtime improves thanks to reduced I/O and efficient encoding.\n",
        "- Choosing the right storage format is a practical lever for greener data engineering.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
