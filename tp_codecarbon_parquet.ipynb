{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "- See how **storage formats** (CSV vs Parquet) affect performance and energy.\n",
    "- Instrument data pipelines with **CodeCarbon** to measure runtime and CO\u2082.\n",
    "- Compare two runs of the same pipeline that differ only by file format.\n",
    "- Explain results in terms of *I/O*, compression, and greener ETL choices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "We benchmark the existing CSV-based books and reviews pipeline against a functionally equivalent Parquet pipeline.\n",
    "The goal is to show whether switching to a columnar, compressed format reduces runtime, file size, and estimated emissions for the same analytical workload.\n",
    "Results support a recommendation on greener storage choices for downstream analytics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets Overview\n",
    "\n",
    "- `books.csv` \u2014 bibliographic metadata with fields such as `Title`, `Authors`, `Publisher`, `PublishedDate`, and `Categories`.\n",
    "- `reviews.csv` \u2014 user feedback that includes `Id`, `Title`, `Price`, `User_id`, `profileName`, `review/score`, `review/text`, and timestamps.\n",
    "\n",
    "The helper cell below ensures sample files exist (for a self-contained demo) and previews the first rows of each dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8899da61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gaurav chugh\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Dependencies are managed by the host environment.\n",
    "# Install pandas, pyarrow, matplotlib, plotly, and codecarbon before running if they are missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 All optional dependencies imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "DEPENDENCIES = {\n",
    "    \"pandas\": \"pandas\",\n",
    "    \"matplotlib\": \"matplotlib\",\n",
    "    \"pyarrow\": \"pyarrow\",\n",
    "    \"numpy\": \"numpy\",\n",
    "    \"codecarbon\": \"codecarbon\",\n",
    "    \"plotly\": \"plotly\",\n",
    "}\n",
    "loaded_modules: Dict[str, object] = {}\n",
    "missing_dependencies: List[str] = []\n",
    "\n",
    "for module_name, package_name in DEPENDENCIES.items():\n",
    "    try:\n",
    "        loaded_modules[module_name] = importlib.import_module(module_name)\n",
    "    except ImportError:\n",
    "        missing_dependencies.append(package_name)\n",
    "\n",
    "if missing_dependencies:\n",
    "    print(\"\u26a0\ufe0f Optional dependencies missing:\", \", \".join(sorted(set(missing_dependencies))))\n",
    "else:\n",
    "    print(\"\u2705 All optional dependencies imported successfully.\")\n",
    "\n",
    "pd = loaded_modules.get(\"pandas\")\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt  # type: ignore\n",
    "    loaded_modules[\"matplotlib\"] = plt\n",
    "except ImportError:\n",
    "    loaded_modules[\"matplotlib\"] = None\n",
    "\n",
    "try:\n",
    "    import plotly.express as px  # type: ignore\n",
    "    loaded_modules[\"plotly\"] = px\n",
    "except ImportError:\n",
    "    loaded_modules[\"plotly\"] = None\n",
    "\n",
    "plt = loaded_modules.get(\"matplotlib\")\n",
    "px = loaded_modules.get(\"plotly\")\n",
    "np = loaded_modules.get(\"numpy\")\n",
    "codecarbon_module = loaded_modules.get(\"codecarbon\")\n",
    "\n",
    "BASE_PATH = Path(\".\")\n",
    "DATA_DIR = BASE_PATH / \"data\"\n",
    "OUTPUTS_DIR = BASE_PATH / \"outputs\"\n",
    "ANALYSIS_DIR = BASE_PATH / \"analysis\"\n",
    "\n",
    "for directory in (OUTPUTS_DIR, ANALYSIS_DIR):\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAW_BOOKS_PATH = DATA_DIR / \"books_data.csv\"\n",
    "RAW_REVIEWS_PATH = DATA_DIR / \"Books_rating.csv\"\n",
    "PARQUET_BOOKS_PATH = DATA_DIR / \"books_data.parquet\"\n",
    "PARQUET_REVIEWS_PATH = DATA_DIR / \"Books_rating.parquet\"\n",
    "\n",
    "PIPELINE_RESULTS: List[Dict[str, object]] = []\n",
    "\n",
    "PREFERRED_POWER_KW = 0.15\n",
    "EMISSIONS_FACTOR_KG_PER_KWH = 0.4\n",
    "\n",
    "def estimate_energy_and_emissions(duration_s: float) -> Tuple[float, float]:\n",
    "    # Return (energy_kwh, emissions_kg) for the provided runtime.\n",
    "    energy_kwh = (duration_s * PREFERRED_POWER_KW) / 3600.0\n",
    "    emissions_kg = energy_kwh * EMISSIONS_FACTOR_KG_PER_KWH\n",
    "    return energy_kwh, emissions_kg\n",
    "\n",
    "if pd is None:\n",
    "    print(\"\u27a1\ufe0f Install pandas to run the benchmarking pipelines.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing existing CSV files from the data/ directory.\n"
     ]
    }
   ],
   "source": [
    "if pd is None:\n",
    "    raise ImportError(\"Pandas is required to execute the benchmarking workflow. Install pandas and rerun the notebook.\")\n",
    "\n",
    "required_inputs = [RAW_BOOKS_PATH, RAW_REVIEWS_PATH]\n",
    "missing_inputs = [path for path in required_inputs if not path.exists()]\n",
    "if missing_inputs:\n",
    "    missing_list = \"\n",
    "\".join(f\" - {path}\" for path in missing_inputs)\n",
    "    raise FileNotFoundError(\n",
    "        \"The following required CSV files were not found:\n",
    "\"\n",
    "        f\"{missing_list}\n",
    "\"\n",
    "        \"Place the datasets in the data/ directory before rerunning the notebook.\"\n",
    "    )\n",
    "\n",
    "print(\"Found raw CSV inputs:\")\n",
    "for path in required_inputs:\n",
    "    try:\n",
    "        size_mb = path.stat().st_size / (1024 * 1024)\n",
    "        print(f\" - {path} ({size_mb:.2f} MB)\")\n",
    "    except OSError:\n",
    "        print(f\" - {path}\")\n",
    "\n",
    "books_preview = pd.read_csv(RAW_BOOKS_PATH, nrows=5)\n",
    "reviews_preview = pd.read_csv(RAW_REVIEWS_PATH, nrows=5)\n",
    "\n",
    "display(books_preview)\n",
    "display(reviews_preview)\n",
    "\n",
    "print(\"Creating or refreshing Parquet copies for downstream benchmarking...\")\n",
    "for source, target in (\n",
    "    (RAW_BOOKS_PATH, PARQUET_BOOKS_PATH),\n",
    "    (RAW_REVIEWS_PATH, PARQUET_REVIEWS_PATH),\n",
    "):\n",
    "    needs_refresh = True\n",
    "    if target.exists():\n",
    "        try:\n",
    "            needs_refresh = source.stat().st_mtime > target.stat().st_mtime\n",
    "        except OSError:\n",
    "            needs_refresh = True\n",
    "        else:\n",
    "            if not needs_refresh:\n",
    "                print(f\" - {target.name} already up to date\")\n",
    "    if needs_refresh:\n",
    "        try:\n",
    "            df_full = pd.read_csv(source)\n",
    "            df_full.to_parquet(target, index=False)\n",
    "            print(f\" - {target.name} regenerated from {source.name}\")\n",
    "        except Exception as parquet_error:\n",
    "            raise RuntimeError(\n",
    "                f\"Unable to convert {source.name} to Parquet. Ensure pyarrow is installed and the file is readable.\"\n",
    "            ) from parquet_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>description</th>\n",
       "      <th>authors</th>\n",
       "      <th>image</th>\n",
       "      <th>previewLink</th>\n",
       "      <th>publisher</th>\n",
       "      <th>publishedDate</th>\n",
       "      <th>infoLink</th>\n",
       "      <th>categories</th>\n",
       "      <th>ratingsCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Its Only Art If Its Well Hung!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Julie Strain']</td>\n",
       "      <td>http://books.google.com/books/content?id=DykPA...</td>\n",
       "      <td>http://books.google.nl/books?id=DykPAAAACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996</td>\n",
       "      <td>http://books.google.nl/books?id=DykPAAAACAAJ&amp;d...</td>\n",
       "      <td>['Comics &amp; Graphic Novels']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>Philip Nel takes a fascinating look into the k...</td>\n",
       "      <td>['Philip Nel']</td>\n",
       "      <td>http://books.google.com/books/content?id=IjvHQ...</td>\n",
       "      <td>http://books.google.nl/books?id=IjvHQsCn_pgC&amp;p...</td>\n",
       "      <td>A&amp;C Black</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>http://books.google.nl/books?id=IjvHQsCn_pgC&amp;d...</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wonderful Worship in Smaller Churches</td>\n",
       "      <td>This resource includes twelve principles in un...</td>\n",
       "      <td>['David R. Ray']</td>\n",
       "      <td>http://books.google.com/books/content?id=2tsDA...</td>\n",
       "      <td>http://books.google.nl/books?id=2tsDAAAACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>http://books.google.nl/books?id=2tsDAAAACAAJ&amp;d...</td>\n",
       "      <td>['Religion']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whispers of the Wicked Saints</td>\n",
       "      <td>Julia Thomas finds her life spinning out of co...</td>\n",
       "      <td>['Veronica Haddon']</td>\n",
       "      <td>http://books.google.com/books/content?id=aRSIg...</td>\n",
       "      <td>http://books.google.nl/books?id=aRSIgJlq6JwC&amp;d...</td>\n",
       "      <td>iUniverse</td>\n",
       "      <td>2005-02</td>\n",
       "      <td>http://books.google.nl/books?id=aRSIgJlq6JwC&amp;d...</td>\n",
       "      <td>['Fiction']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nation Dance: Religion, Identity and Cultural ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Edward Long']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://books.google.nl/books?id=399SPgAACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003-03-01</td>\n",
       "      <td>http://books.google.nl/books?id=399SPgAACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                     Its Only Art If Its Well Hung!   \n",
       "1                           Dr. Seuss: American Icon   \n",
       "2              Wonderful Worship in Smaller Churches   \n",
       "3                      Whispers of the Wicked Saints   \n",
       "4  Nation Dance: Religion, Identity and Cultural ...   \n",
       "\n",
       "                                         description              authors  \\\n",
       "0                                                NaN     ['Julie Strain']   \n",
       "1  Philip Nel takes a fascinating look into the k...       ['Philip Nel']   \n",
       "2  This resource includes twelve principles in un...     ['David R. Ray']   \n",
       "3  Julia Thomas finds her life spinning out of co...  ['Veronica Haddon']   \n",
       "4                                                NaN      ['Edward Long']   \n",
       "\n",
       "                                               image  \\\n",
       "0  http://books.google.com/books/content?id=DykPA...   \n",
       "1  http://books.google.com/books/content?id=IjvHQ...   \n",
       "2  http://books.google.com/books/content?id=2tsDA...   \n",
       "3  http://books.google.com/books/content?id=aRSIg...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         previewLink  publisher publishedDate  \\\n",
       "0  http://books.google.nl/books?id=DykPAAAACAAJ&d...        NaN          1996   \n",
       "1  http://books.google.nl/books?id=IjvHQsCn_pgC&p...  A&C Black    2005-01-01   \n",
       "2  http://books.google.nl/books?id=2tsDAAAACAAJ&d...        NaN          2000   \n",
       "3  http://books.google.nl/books?id=aRSIgJlq6JwC&d...  iUniverse       2005-02   \n",
       "4  http://books.google.nl/books?id=399SPgAACAAJ&d...        NaN    2003-03-01   \n",
       "\n",
       "                                            infoLink  \\\n",
       "0  http://books.google.nl/books?id=DykPAAAACAAJ&d...   \n",
       "1  http://books.google.nl/books?id=IjvHQsCn_pgC&d...   \n",
       "2  http://books.google.nl/books?id=2tsDAAAACAAJ&d...   \n",
       "3  http://books.google.nl/books?id=aRSIgJlq6JwC&d...   \n",
       "4  http://books.google.nl/books?id=399SPgAACAAJ&d...   \n",
       "\n",
       "                      categories  ratingsCount  \n",
       "0    ['Comics & Graphic Novels']           NaN  \n",
       "1  ['Biography & Autobiography']           NaN  \n",
       "2                   ['Religion']           NaN  \n",
       "3                    ['Fiction']           NaN  \n",
       "4                            NaN           NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>User_id</th>\n",
       "      <th>profileName</th>\n",
       "      <th>review/helpfulness</th>\n",
       "      <th>review/score</th>\n",
       "      <th>review/time</th>\n",
       "      <th>review/summary</th>\n",
       "      <th>review/text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1882931173</td>\n",
       "      <td>Its Only Art If Its Well Hung!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AVCGYZL8FQQTD</td>\n",
       "      <td>Jim of Oz \"jim-of-oz\"</td>\n",
       "      <td>7/7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>940636800</td>\n",
       "      <td>Nice collection of Julie Strain images</td>\n",
       "      <td>This is only for Julie Strain fans. It's a col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A30TK6U7DNS82R</td>\n",
       "      <td>Kevin Killian</td>\n",
       "      <td>10/10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1095724800</td>\n",
       "      <td>Really Enjoyed It</td>\n",
       "      <td>I don't care much for Dr. Seuss but after read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A3UH4UZ4RSVO82</td>\n",
       "      <td>John Granger</td>\n",
       "      <td>10/11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1078790400</td>\n",
       "      <td>Essential for every personal and Public Library</td>\n",
       "      <td>If people become the books they read and if \"t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A2MVUWT453QH61</td>\n",
       "      <td>Roy E. Perry \"amateur philosopher\"</td>\n",
       "      <td>7/7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1090713600</td>\n",
       "      <td>Phlip Nel gives silly Seuss a serious treatment</td>\n",
       "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A22X4XUPKF66MR</td>\n",
       "      <td>D. H. Richards \"ninthwavestore\"</td>\n",
       "      <td>3/3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1107993600</td>\n",
       "      <td>Good academic overview</td>\n",
       "      <td>Philip Nel - Dr. Seuss: American IconThis is b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id                           Title  Price         User_id  \\\n",
       "0  1882931173  Its Only Art If Its Well Hung!    NaN   AVCGYZL8FQQTD   \n",
       "1  0826414346        Dr. Seuss: American Icon    NaN  A30TK6U7DNS82R   \n",
       "2  0826414346        Dr. Seuss: American Icon    NaN  A3UH4UZ4RSVO82   \n",
       "3  0826414346        Dr. Seuss: American Icon    NaN  A2MVUWT453QH61   \n",
       "4  0826414346        Dr. Seuss: American Icon    NaN  A22X4XUPKF66MR   \n",
       "\n",
       "                          profileName review/helpfulness  review/score  \\\n",
       "0               Jim of Oz \"jim-of-oz\"                7/7           4.0   \n",
       "1                       Kevin Killian              10/10           5.0   \n",
       "2                        John Granger              10/11           5.0   \n",
       "3  Roy E. Perry \"amateur philosopher\"                7/7           4.0   \n",
       "4     D. H. Richards \"ninthwavestore\"                3/3           4.0   \n",
       "\n",
       "   review/time                                   review/summary  \\\n",
       "0    940636800           Nice collection of Julie Strain images   \n",
       "1   1095724800                                Really Enjoyed It   \n",
       "2   1078790400  Essential for every personal and Public Library   \n",
       "3   1090713600  Phlip Nel gives silly Seuss a serious treatment   \n",
       "4   1107993600                           Good academic overview   \n",
       "\n",
       "                                         review/text  \n",
       "0  This is only for Julie Strain fans. It's a col...  \n",
       "1  I don't care much for Dr. Seuss but after read...  \n",
       "2  If people become the books they read and if \"t...  \n",
       "3  Theodore Seuss Geisel (1904-1991), aka &quot;D...  \n",
       "4  Philip Nel - Dr. Seuss: American IconThis is b...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 212404 book rows.\n",
      "Loaded 3000000 review rows.\n"
     ]
    }
   ],
   "source": [
    "## Data validation and parquet preparation\n",
    "The CSV datasets are validated for presence, previewed, and converted into optimised Parquet copies so both pipelines analyse the same source content.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Design\n",
    "\n",
    "1. Load raw CSV assets for books and reviews.\n",
    "2. Clean textual fields and normalise categories/authors.\n",
    "3. Join the datasets on `Title`.\n",
    "4. Compute metrics (ratings per author, reviews per publisher, top categories, review length stats, frequent keywords).\n",
    "5. Persist the merged dataset in the chosen format.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165f8acc",
   "metadata": {},
   "source": [
    "### Pipeline A \u2013 CSV & Pipeline B \u2013 Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>description</th>\n",
       "      <th>authors</th>\n",
       "      <th>image</th>\n",
       "      <th>previewLink</th>\n",
       "      <th>publisher</th>\n",
       "      <th>publishedDate</th>\n",
       "      <th>infoLink</th>\n",
       "      <th>categories</th>\n",
       "      <th>ratingsCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Its Only Art If Its Well Hung!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Julie Strain']</td>\n",
       "      <td>http://books.google.com/books/content?id=DykPA...</td>\n",
       "      <td>http://books.google.nl/books?id=DykPAAAACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996</td>\n",
       "      <td>http://books.google.nl/books?id=DykPAAAACAAJ&amp;d...</td>\n",
       "      <td>['Comics &amp; Graphic Novels']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>Philip Nel takes a fascinating look into the k...</td>\n",
       "      <td>['Philip Nel']</td>\n",
       "      <td>http://books.google.com/books/content?id=IjvHQ...</td>\n",
       "      <td>http://books.google.nl/books?id=IjvHQsCn_pgC&amp;p...</td>\n",
       "      <td>A&amp;C Black</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>http://books.google.nl/books?id=IjvHQsCn_pgC&amp;d...</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wonderful Worship in Smaller Churches</td>\n",
       "      <td>This resource includes twelve principles in un...</td>\n",
       "      <td>['David R. Ray']</td>\n",
       "      <td>http://books.google.com/books/content?id=2tsDA...</td>\n",
       "      <td>http://books.google.nl/books?id=2tsDAAAACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>http://books.google.nl/books?id=2tsDAAAACAAJ&amp;d...</td>\n",
       "      <td>['Religion']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whispers of the Wicked Saints</td>\n",
       "      <td>Julia Thomas finds her life spinning out of co...</td>\n",
       "      <td>['Veronica Haddon']</td>\n",
       "      <td>http://books.google.com/books/content?id=aRSIg...</td>\n",
       "      <td>http://books.google.nl/books?id=aRSIgJlq6JwC&amp;d...</td>\n",
       "      <td>iUniverse</td>\n",
       "      <td>2005-02</td>\n",
       "      <td>http://books.google.nl/books?id=aRSIgJlq6JwC&amp;d...</td>\n",
       "      <td>['Fiction']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nation Dance: Religion, Identity and Cultural ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Edward Long']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://books.google.nl/books?id=399SPgAACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003-03-01</td>\n",
       "      <td>http://books.google.nl/books?id=399SPgAACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                     Its Only Art If Its Well Hung!   \n",
       "1                           Dr. Seuss: American Icon   \n",
       "2              Wonderful Worship in Smaller Churches   \n",
       "3                      Whispers of the Wicked Saints   \n",
       "4  Nation Dance: Religion, Identity and Cultural ...   \n",
       "\n",
       "                                         description              authors  \\\n",
       "0                                                NaN     ['Julie Strain']   \n",
       "1  Philip Nel takes a fascinating look into the k...       ['Philip Nel']   \n",
       "2  This resource includes twelve principles in un...     ['David R. Ray']   \n",
       "3  Julia Thomas finds her life spinning out of co...  ['Veronica Haddon']   \n",
       "4                                                NaN      ['Edward Long']   \n",
       "\n",
       "                                               image  \\\n",
       "0  http://books.google.com/books/content?id=DykPA...   \n",
       "1  http://books.google.com/books/content?id=IjvHQ...   \n",
       "2  http://books.google.com/books/content?id=2tsDA...   \n",
       "3  http://books.google.com/books/content?id=aRSIg...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         previewLink  publisher publishedDate  \\\n",
       "0  http://books.google.nl/books?id=DykPAAAACAAJ&d...        NaN          1996   \n",
       "1  http://books.google.nl/books?id=IjvHQsCn_pgC&p...  A&C Black    2005-01-01   \n",
       "2  http://books.google.nl/books?id=2tsDAAAACAAJ&d...        NaN          2000   \n",
       "3  http://books.google.nl/books?id=aRSIgJlq6JwC&d...  iUniverse       2005-02   \n",
       "4  http://books.google.nl/books?id=399SPgAACAAJ&d...        NaN    2003-03-01   \n",
       "\n",
       "                                            infoLink  \\\n",
       "0  http://books.google.nl/books?id=DykPAAAACAAJ&d...   \n",
       "1  http://books.google.nl/books?id=IjvHQsCn_pgC&d...   \n",
       "2  http://books.google.nl/books?id=2tsDAAAACAAJ&d...   \n",
       "3  http://books.google.nl/books?id=aRSIgJlq6JwC&d...   \n",
       "4  http://books.google.nl/books?id=399SPgAACAAJ&d...   \n",
       "\n",
       "                      categories  ratingsCount  \n",
       "0    ['Comics & Graphic Novels']           NaN  \n",
       "1  ['Biography & Autobiography']           NaN  \n",
       "2                   ['Religion']           NaN  \n",
       "3                    ['Fiction']           NaN  \n",
       "4                            NaN           NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>User_id</th>\n",
       "      <th>profileName</th>\n",
       "      <th>review/helpfulness</th>\n",
       "      <th>review/score</th>\n",
       "      <th>review/time</th>\n",
       "      <th>review/summary</th>\n",
       "      <th>review/text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1882931173</td>\n",
       "      <td>Its Only Art If Its Well Hung!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AVCGYZL8FQQTD</td>\n",
       "      <td>Jim of Oz \"jim-of-oz\"</td>\n",
       "      <td>7/7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>940636800</td>\n",
       "      <td>Nice collection of Julie Strain images</td>\n",
       "      <td>This is only for Julie Strain fans. It's a col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A30TK6U7DNS82R</td>\n",
       "      <td>Kevin Killian</td>\n",
       "      <td>10/10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1095724800</td>\n",
       "      <td>Really Enjoyed It</td>\n",
       "      <td>I don't care much for Dr. Seuss but after read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A3UH4UZ4RSVO82</td>\n",
       "      <td>John Granger</td>\n",
       "      <td>10/11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1078790400</td>\n",
       "      <td>Essential for every personal and Public Library</td>\n",
       "      <td>If people become the books they read and if \"t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A2MVUWT453QH61</td>\n",
       "      <td>Roy E. Perry \"amateur philosopher\"</td>\n",
       "      <td>7/7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1090713600</td>\n",
       "      <td>Phlip Nel gives silly Seuss a serious treatment</td>\n",
       "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A22X4XUPKF66MR</td>\n",
       "      <td>D. H. Richards \"ninthwavestore\"</td>\n",
       "      <td>3/3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1107993600</td>\n",
       "      <td>Good academic overview</td>\n",
       "      <td>Philip Nel - Dr. Seuss: American IconThis is b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id                           Title  Price         User_id  \\\n",
       "0  1882931173  Its Only Art If Its Well Hung!    NaN   AVCGYZL8FQQTD   \n",
       "1  0826414346        Dr. Seuss: American Icon    NaN  A30TK6U7DNS82R   \n",
       "2  0826414346        Dr. Seuss: American Icon    NaN  A3UH4UZ4RSVO82   \n",
       "3  0826414346        Dr. Seuss: American Icon    NaN  A2MVUWT453QH61   \n",
       "4  0826414346        Dr. Seuss: American Icon    NaN  A22X4XUPKF66MR   \n",
       "\n",
       "                          profileName review/helpfulness  review/score  \\\n",
       "0               Jim of Oz \"jim-of-oz\"                7/7           4.0   \n",
       "1                       Kevin Killian              10/10           5.0   \n",
       "2                        John Granger              10/11           5.0   \n",
       "3  Roy E. Perry \"amateur philosopher\"                7/7           4.0   \n",
       "4     D. H. Richards \"ninthwavestore\"                3/3           4.0   \n",
       "\n",
       "   review/time                                   review/summary  \\\n",
       "0    940636800           Nice collection of Julie Strain images   \n",
       "1   1095724800                                Really Enjoyed It   \n",
       "2   1078790400  Essential for every personal and Public Library   \n",
       "3   1090713600  Phlip Nel gives silly Seuss a serious treatment   \n",
       "4   1107993600                           Good academic overview   \n",
       "\n",
       "                                         review/text  \n",
       "0  This is only for Julie Strain fans. It's a col...  \n",
       "1  I don't care much for Dr. Seuss but after read...  \n",
       "2  If people become the books they read and if \"t...  \n",
       "3  Theodore Seuss Geisel (1904-1991), aka &quot;D...  \n",
       "4  Philip Nel - Dr. Seuss: American IconThis is b...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 212404 book rows.\n",
      "Loaded 3000000 review rows.\n"
     ]
    }
   ],
   "source": [
    "if pd is None:\n",
    "    raise ImportError(\"Install pandas to run the benchmarking pipelines.\")\n",
    "\n",
    "TaskBreakdown = Dict[str, object]\n",
    "\n",
    "def create_tracker(project_name: str):\n",
    "    emissions_dir = ANALYSIS_DIR / \"emissions\"\n",
    "    emissions_dir.mkdir(parents=True, exist_ok=True)\n",
    "    output_file = f\"{project_name}_emissions.jsonl\"\n",
    "    if codecarbon_module is not None:\n",
    "        try:\n",
    "            tracker = codecarbon_module.EmissionsTracker(\n",
    "                project_name=project_name,\n",
    "                output_dir=str(emissions_dir),\n",
    "                output_file=output_file,\n",
    "            )\n",
    "            return tracker\n",
    "        except Exception as tracker_error:\n",
    "            print(f\"Falling back to lightweight tracker because CodeCarbon initialisation failed: {tracker_error}\")\n",
    "\n",
    "    class FallbackTracker:\n",
    "        def __init__(self, project_name: str, target_dir: Path, file_name: str) -> None:\n",
    "            self.project_name = project_name\n",
    "            self.target_dir = target_dir\n",
    "            self.file_name = file_name\n",
    "            self._start: Optional[float] = None\n",
    "\n",
    "        def start(self) -> float:\n",
    "            self._start = time.perf_counter()\n",
    "            return self._start\n",
    "\n",
    "        def stop(self) -> float:\n",
    "            end = time.perf_counter()\n",
    "            duration = end - (self._start or end)\n",
    "            emissions = duration * 0.00012\n",
    "            self._persist(\n",
    "                {\n",
    "                    \"project_name\": self.project_name,\n",
    "                    \"duration_s\": duration,\n",
    "                    \"emissions_kg\": emissions,\n",
    "                    \"timestamp\": datetime.utcnow().isoformat(),\n",
    "                }\n",
    "            )\n",
    "            return emissions\n",
    "\n",
    "        def _persist(self, payload: Dict[str, object]) -> None:\n",
    "            try:\n",
    "                self.target_dir.mkdir(parents=True, exist_ok=True)\n",
    "                with (self.target_dir / self.file_name).open(\"a\", encoding=\"utf-8\") as handle:\n",
    "                    handle.write(json.dumps(payload) + \"\n",
    "\")\n",
    "            except Exception as persist_error:\n",
    "                print(f\"Could not persist fallback emissions data: {persist_error}\")\n",
    "\n",
    "    return FallbackTracker(project_name, emissions_dir, output_file)\n",
    "\n",
    "def _column_with_default(df: 'pd.DataFrame', column: str, default) -> 'pd.Series':\n",
    "    if column in df:\n",
    "        return df[column]\n",
    "    return pd.Series(default, index=df.index)\n",
    "\n",
    "\n",
    "def clean_books(df: 'pd.DataFrame') -> 'pd.DataFrame':\n",
    "    cleaned = df.copy()\n",
    "    cleaned['Authors'] = _column_with_default(cleaned, 'Authors', 'Unknown').fillna('Unknown').astype(str)\n",
    "    cleaned[\"Authors\"] = cleaned[\"Authors\"].str.title()\n",
    "    cleaned['Publisher'] = _column_with_default(cleaned, 'Publisher', 'Unknown').fillna('Unknown').astype(str)\n",
    "    cleaned['Categories'] = _column_with_default(cleaned, 'Categories', 'misc').fillna('misc').astype(str)\n",
    "    cleaned[\"PublishedDate\"] = pd.to_datetime(cleaned.get(\"PublishedDate\"), errors=\"coerce\")\n",
    "    cleaned[\"RatingsCount\"] = pd.to_numeric(cleaned.get(\"RatingsCount\"), errors=\"coerce\").fillna(0).astype(int)\n",
    "    cleaned[\"AverageRating\"] = pd.to_numeric(cleaned.get(\"AverageRating\"), errors=\"coerce\")\n",
    "    return cleaned\n",
    "\n",
    "def clean_reviews(df: 'pd.DataFrame') -> 'pd.DataFrame':\n",
    "    cleaned = df.copy()\n",
    "    cleaned = cleaned.rename(columns={\"profileName\": \"ProfileName\"})\n",
    "    cleaned['review/text'] = _column_with_default(cleaned, 'review/text', '').fillna('').astype(str)\n",
    "    cleaned[\"review/score\"] = pd.to_numeric(cleaned.get(\"review/score\"), errors=\"coerce\")\n",
    "    cleaned[\"review/score\"] = cleaned[\"review/score\"].fillna(cleaned[\"review/score\"].mean())\n",
    "    cleaned[\"review/time\"] = pd.to_datetime(cleaned.get(\"review/time\"), unit=\"s\", errors=\"coerce\")\n",
    "    return cleaned\n",
    "\n",
    "def enrich_features(df: 'pd.DataFrame') -> 'pd.DataFrame':\n",
    "    enriched = df.copy()\n",
    "    enriched[\"review_length\"] = enriched[\"review/text\"].str.split().map(len)\n",
    "    enriched['Categories'] = _column_with_default(enriched, 'Categories', 'misc').fillna('misc')\n",
    "    enriched[\"CategoriesList\"] = (\n",
    "        enriched[\"Categories\"].astype(str).str.split(\"|\").apply(lambda values: [v.strip().lower() for v in values if v])\n",
    "    )\n",
    "    return enriched\n",
    "\n",
    "TASK_REGISTRY = [\n",
    "    (\n",
    "        \"avg_rating_per_author\",\n",
    "        \"Average rating per author\",\n",
    "        lambda df: df.groupby(\"Authors\")[\"review/score\"].mean().reset_index().rename(\n",
    "            columns={\"review/score\": \"average_rating\"}\n",
    "        ).sort_values(\"average_rating\", ascending=False),\n",
    "    ),\n",
    "    (\n",
    "        \"reviews_per_publisher\",\n",
    "        \"Reviews per publisher\",\n",
    "        lambda df: df.groupby(\"Publisher\")[\"Id\"].count().reset_index().rename(\n",
    "            columns={\"Id\": \"review_count\"}\n",
    "        ).sort_values(\"review_count\", ascending=False),\n",
    "    ),\n",
    "    (\n",
    "        \"top_categories\",\n",
    "        \"Top 10 most-reviewed categories\",\n",
    "        lambda df: df.explode(\"CategoriesList\").groupby(\"CategoriesList\")[\"Id\"].count().reset_index().rename(\n",
    "            columns={\"CategoriesList\": \"Category\", \"Id\": \"review_count\"}\n",
    "        ).sort_values(\"review_count\", ascending=False).head(10),\n",
    "    ),\n",
    "    (\n",
    "        \"avg_review_length\",\n",
    "        \"Average review length\",\n",
    "        lambda df: pd.DataFrame(\n",
    "            [\n",
    "                {\n",
    "                    \"metric\": \"average_review_length\",\n",
    "                    \"value\": df[\"review_length\"].mean(),\n",
    "                }\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"top_keywords\",\n",
    "        \"Most frequent review keywords\",\n",
    "        lambda df: pd.DataFrame(\n",
    "            Counter(\" \".join(df[\"review/text\"]).lower().split()).most_common(20),\n",
    "            columns=[\"keyword\", \"occurrences\"],\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "def compute_metrics(df: 'pd.DataFrame') -> Tuple[Dict[str, 'pd.DataFrame'], List[TaskBreakdown]]:\n",
    "    metrics: Dict[str, 'pd.DataFrame'] = {}\n",
    "    breakdown: List[TaskBreakdown] = []\n",
    "    for task_id, task_label, task_fn in TASK_REGISTRY:\n",
    "        task_start = time.perf_counter()\n",
    "        frame = task_fn(df)\n",
    "        duration = time.perf_counter() - task_start\n",
    "        energy_kwh, emissions_kg = estimate_energy_and_emissions(duration)\n",
    "        metrics[task_id] = frame\n",
    "        breakdown.append(\n",
    "            {\n",
    "                \"task_id\": task_id,\n",
    "                \"task_label\": task_label,\n",
    "                \"duration_s\": duration,\n",
    "                \"energy_kwh\": energy_kwh,\n",
    "                \"emissions_kg\": emissions_kg,\n",
    "                \"output_rows\": int(len(frame)),\n",
    "            }\n",
    "        )\n",
    "    return metrics, breakdown\n",
    "\n",
    "def persist_outputs(format_name: str, df: 'pd.DataFrame', metrics: Dict[str, 'pd.DataFrame'], output_path: Path, writer) -> None:\n",
    "    try:\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        writer(df, output_path)\n",
    "        print(f\"Saved merged dataset to {output_path}\")\n",
    "    except Exception as write_error:\n",
    "        print(f\"Failed to persist merged dataset: {write_error}\")\n",
    "    prefix = f\"{format_name}_{output_path.stem}\"\n",
    "    for name, frame in metrics.items():\n",
    "        target = ANALYSIS_DIR / f\"{prefix}_{name}.csv\"\n",
    "        try:\n",
    "            frame.to_csv(target, index=False)\n",
    "            print(f\"Exported metric '{name}' to {target}\")\n",
    "        except Exception as export_error:\n",
    "            print(f\"Could not export metric {name}: {export_error}\")\n",
    "\n",
    "def load_from_csv() -> Tuple['pd.DataFrame', 'pd.DataFrame']:\n",
    "    return pd.read_csv(RAW_BOOKS_PATH), pd.read_csv(RAW_REVIEWS_PATH)\n",
    "\n",
    "def load_from_parquet() -> Tuple['pd.DataFrame', 'pd.DataFrame']:\n",
    "    return pd.read_parquet(PARQUET_BOOKS_PATH), pd.read_parquet(PARQUET_REVIEWS_PATH)\n",
    "\n",
    "def write_csv(df: 'pd.DataFrame', path: Path) -> None:\n",
    "    df.to_csv(path, index=False)\n",
    "\n",
    "def write_parquet(df: 'pd.DataFrame', path: Path) -> None:\n",
    "    try:\n",
    "        df.to_parquet(path, index=False, compression=\"snappy\")\n",
    "    except Exception as parquet_error:\n",
    "        print(f\"Snappy compression failed ({parquet_error}); retrying without compression.\")\n",
    "        df.to_parquet(path, index=False)\n",
    "\n",
    "def run_pipeline(format_name: str, loader_callable, writer_callable, output_name: str, project_name: str) -> Dict[str, object]:\n",
    "    tracker = create_tracker(project_name)\n",
    "    start = time.perf_counter()\n",
    "    emissions_from_tracker = math.nan\n",
    "    error: Optional[str] = None\n",
    "    merged_df = None\n",
    "    metrics: Dict[str, 'pd.DataFrame'] = {}\n",
    "    task_breakdown: List[TaskBreakdown] = []\n",
    "    try:\n",
    "        tracker.start()\n",
    "        books_df, reviews_df = loader_callable()\n",
    "        books_df = clean_books(books_df)\n",
    "        reviews_df = clean_reviews(reviews_df)\n",
    "        merged_df = enrich_features(reviews_df.merge(books_df, on=\"Title\", how=\"inner\", suffixes=(\"_review\", \"_book\")))\n",
    "        metrics, task_breakdown = compute_metrics(merged_df)\n",
    "        persist_outputs(format_name, merged_df, metrics, OUTPUTS_DIR / output_name, writer_callable)\n",
    "    except Exception as pipeline_error:\n",
    "        error = str(pipeline_error)\n",
    "        print(f\"[{format_name}] Pipeline encountered an issue: {pipeline_error}\")\n",
    "    finally:\n",
    "        duration = time.perf_counter() - start\n",
    "        try:\n",
    "            emissions_from_tracker = tracker.stop()\n",
    "        except Exception as tracker_error:\n",
    "            print(f\"[{format_name}] Unable to obtain emissions from tracker: {tracker_error}\")\n",
    "        energy_kwh, estimated_emissions = estimate_energy_and_emissions(duration)\n",
    "        emissions_kg = (\n",
    "            emissions_from_tracker if isinstance(emissions_from_tracker, (int, float)) and not math.isnan(emissions_from_tracker)\n",
    "            else estimated_emissions\n",
    "        )\n",
    "        result = {\n",
    "            \"format\": format_name,\n",
    "            \"runtime_s\": duration,\n",
    "            \"energy_kwh\": energy_kwh,\n",
    "            \"emissions_kg\": emissions_kg,\n",
    "            \"row_count\": int(0 if merged_df is None else len(merged_df)),\n",
    "            \"error\": error,\n",
    "            \"metrics\": metrics,\n",
    "            \"task_breakdown\": task_breakdown,\n",
    "            \"output_path\": str(OUTPUTS_DIR / output_name),\n",
    "        }\n",
    "        PIPELINE_RESULTS.append(result)\n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11490ad",
   "metadata": {},
   "source": [
    "# === Task 1 \u2014 CSV Baseline ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 10:41:28] Multiple instances of codecarbon are allowed to run at the same time.\n",
      "[codecarbon INFO @ 10:41:28] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 10:41:28] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 10:41:30] We saw that you have a Intel(R) Core(TM) Ultra 9 185H but we don't know it. Please contact us.\n",
      "[codecarbon WARNING @ 10:41:30] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
      " Windows OS detected: Please install Intel Power Gadget to measure CPU\n",
      "\n",
      "[codecarbon INFO @ 10:41:30] CPU Model on constant consumption mode: Intel(R) Core(TM) Ultra 9 185H\n",
      "[codecarbon WARNING @ 10:41:30] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon INFO @ 10:41:30] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 10:41:30] No GPU found.\n",
      "[codecarbon INFO @ 10:41:30] The below tracking methods have been set up:\n",
      "                RAM Tracking Method: RAM power estimation model\n",
      "                CPU Tracking Method: global constant\n",
      "                GPU Tracking Method: Unspecified\n",
      "            \n",
      "[codecarbon INFO @ 10:41:30] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 10:41:30]   Platform system: Windows-11-10.0.26200-SP0\n",
      "[codecarbon INFO @ 10:41:30]   Python version: 3.12.6\n",
      "[codecarbon INFO @ 10:41:30]   CodeCarbon version: 3.0.8\n",
      "[codecarbon INFO @ 10:41:30]   Available RAM : 31.435 GB\n",
      "[codecarbon INFO @ 10:41:30]   CPU count: 22 thread(s) in 22 physical CPU(s)\n",
      "[codecarbon INFO @ 10:41:30]   CPU model: Intel(R) Core(TM) Ultra 9 185H\n",
      "[codecarbon INFO @ 10:41:30]   GPU count: None\n",
      "[codecarbon INFO @ 10:41:30]   GPU model: None\n",
      "[codecarbon INFO @ 10:41:31] Emissions data (if any) will be saved to file c:\\Users\\Gaurav Chugh\\source\\GreenComputing_TP3\\analysis\\emissions\\csv_pipeline_emissions.jsonl\n",
      "[codecarbon INFO @ 10:41:33] Energy consumed for RAM : 0.000014 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 10:41:33] Delta energy consumed for CPU with constant : 0.000029 kWh, power : 42.5 W\n",
      "[codecarbon INFO @ 10:41:33] Energy consumed for All CPU : 0.000029 kWh\n",
      "[codecarbon INFO @ 10:41:33] 0.000042 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[csv] Pipeline encountered an issue: 'Authors'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "csv_result = run_pipeline(\n",
    "    \"csv\",\n",
    "    load_from_csv,\n",
    "    write_csv,\n",
    "    \"merged_books_reviews_csv.csv\",\n",
    "    \"csv_pipeline\",\n",
    ")\n",
    "pd.DataFrame([csv_result]).drop(columns=[\"metrics\", \"task_breakdown\"]).to_csv(ANALYSIS_DIR / \"csv_pipeline_summary.csv\", index=False)\n",
    "csv_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# === Task 2 \u2014 Parquet Pipeline ===\n",
    "### Pipeline B \u2013 Parquet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 10:41:33] Multiple instances of codecarbon are allowed to run at the same time.\n",
      "[codecarbon INFO @ 10:41:33] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 10:41:33] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 10:41:35] We saw that you have a Intel(R) Core(TM) Ultra 9 185H but we don't know it. Please contact us.\n",
      "[codecarbon WARNING @ 10:41:35] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
      " Windows OS detected: Please install Intel Power Gadget to measure CPU\n",
      "\n",
      "[codecarbon INFO @ 10:41:35] CPU Model on constant consumption mode: Intel(R) Core(TM) Ultra 9 185H\n",
      "[codecarbon WARNING @ 10:41:35] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon INFO @ 10:41:35] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 10:41:35] No GPU found.\n",
      "[codecarbon INFO @ 10:41:35] The below tracking methods have been set up:\n",
      "                RAM Tracking Method: RAM power estimation model\n",
      "                CPU Tracking Method: global constant\n",
      "                GPU Tracking Method: Unspecified\n",
      "            \n",
      "[codecarbon INFO @ 10:41:35] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 10:41:35]   Platform system: Windows-11-10.0.26200-SP0\n",
      "[codecarbon INFO @ 10:41:35]   Python version: 3.12.6\n",
      "[codecarbon INFO @ 10:41:35]   CodeCarbon version: 3.0.8\n",
      "[codecarbon INFO @ 10:41:35]   Available RAM : 31.435 GB\n",
      "[codecarbon INFO @ 10:41:35]   CPU count: 22 thread(s) in 22 physical CPU(s)\n",
      "[codecarbon INFO @ 10:41:35]   CPU model: Intel(R) Core(TM) Ultra 9 185H\n",
      "[codecarbon INFO @ 10:41:35]   GPU count: None\n",
      "[codecarbon INFO @ 10:41:35]   GPU model: None\n",
      "[codecarbon INFO @ 10:41:36] Emissions data (if any) will be saved to file c:\\Users\\Gaurav Chugh\\source\\GreenComputing_TP3\\analysis\\emissions\\parquet_pipeline_emissions.jsonl\n",
      "[codecarbon INFO @ 10:41:38] Energy consumed for RAM : 0.000013 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 10:41:38] Delta energy consumed for CPU with constant : 0.000028 kWh, power : 42.5 W\n",
      "[codecarbon INFO @ 10:41:38] Energy consumed for All CPU : 0.000028 kWh\n",
      "[codecarbon INFO @ 10:41:38] 0.000041 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[parquet] Pipeline encountered an issue: 'Authors'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parquet_result = run_pipeline(\n",
    "    \"parquet\",\n",
    "    load_from_parquet,\n",
    "    write_parquet,\n",
    "    \"merged_books_reviews_parquet.parquet\",\n",
    "    \"parquet_pipeline\",\n",
    ")\n",
    "pd.DataFrame([parquet_result]).drop(columns=[\"metrics\", \"task_breakdown\"]).to_csv(ANALYSIS_DIR / \"parquet_pipeline_summary.csv\", index=False)\n",
    "parquet_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 \u2014 Comparison and Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format</th>\n",
       "      <th>runtime_s</th>\n",
       "      <th>emissions_kg</th>\n",
       "      <th>error</th>\n",
       "      <th>row_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>csv</td>\n",
       "      <td>2.444413</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>'Authors'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>parquet</td>\n",
       "      <td>2.382503</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>'Authors'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    format  runtime_s  emissions_kg      error  row_count\n",
       "0      csv   2.444413      0.000002  'Authors'          0\n",
       "1  parquet   2.382503      0.000002  'Authors'          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison artefacts saved to analysis\\format_comparison.csv and analysis\\format_comparison.png.\n"
     ]
    }
   ],
   "source": [
    "summary_df = pd.DataFrame([\n",
    "    {k: v for k, v in result.items() if k not in (\"metrics\", \"task_breakdown\")}\n",
    "    for result in PIPELINE_RESULTS\n",
    "])\n",
    "\n",
    "display(summary_df)\n",
    "analysis_path = ANALYSIS_DIR / \"format_comparison.csv\"\n",
    "summary_df.to_csv(analysis_path, index=False)\n",
    "\n",
    "if plt is not None and not summary_df.empty:\n",
    "    figure_path = ANALYSIS_DIR / \"format_comparison.png\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    chart_specs = [\n",
    "        (\"runtime_s\", \"Runtime (s)\", \"Runtime by format\", \"#1f77b4\"),\n",
    "        (\"energy_kwh\", \"Energy (kWh)\", \"Energy consumption by format\", \"#ff7f0e\"),\n",
    "        (\"emissions_kg\", \"Emissions (kg CO\u2082)\", \"Carbon emissions by format\", \"#2ca02c\"),\n",
    "    ]\n",
    "    for ax, (column, ylabel, title, color) in zip(axes, chart_specs):\n",
    "        summary_df.plot.bar(x=\"format\", y=column, ax=ax, color=color, legend=False)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"File format\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(figure_path, dpi=150)\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    print(f\"Comparison artefacts saved to {analysis_path} and {figure_path}.\")\n",
    "else:\n",
    "    print(f\"Comparison artefact saved to {analysis_path}.\")\n",
    "\n",
    "task_rows = []\n",
    "for result in PIPELINE_RESULTS:\n",
    "    for record in result.get(\"task_breakdown\", []):\n",
    "        enriched = dict(record)\n",
    "        enriched[\"format\"] = result.get(\"format\")\n",
    "        task_rows.append(enriched)\n",
    "\n",
    "task_summary_df = pd.DataFrame(task_rows)\n",
    "task_analysis_path = ANALYSIS_DIR / \"format_task_comparison.csv\"\n",
    "if not task_summary_df.empty:\n",
    "    display(task_summary_df)\n",
    "    task_summary_df.to_csv(task_analysis_path, index=False)\n",
    "    if px is not None:\n",
    "        plotly_fig = px.bar(\n",
    "            task_summary_df,\n",
    "            x=\"task_label\",\n",
    "            y=\"duration_s\",\n",
    "            color=\"format\",\n",
    "            barmode=\"group\",\n",
    "            title=\"Runtime by task and file format\",\n",
    "            labels={\"task_label\": \"Task\", \"duration_s\": \"Runtime (s)\", \"format\": \"Format\"},\n",
    "        )\n",
    "        plotly_path = ANALYSIS_DIR / \"task_runtime_comparison.html\"\n",
    "        plotly_fig.write_html(plotly_path)\n",
    "        print(f\"Plotly runtime comparison saved to {plotly_path}.\")\n",
    "    else:\n",
    "        print(\"Plotly is unavailable; skipping interactive runtime chart export.\")\n",
    "    print(f\"Task-level comparison saved to {task_analysis_path}.\")\n",
    "else:\n",
    "    print(\"No task-level records were generated.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart insights\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if 'summary_df' in globals() and not summary_df.empty:\n",
    "    fastest = summary_df.loc[summary_df['runtime_s'].idxmin()]\n",
    "    slowest = summary_df.loc[summary_df['runtime_s'].idxmax()]\n",
    "    best_energy = summary_df.loc[summary_df['energy_kwh'].idxmin()]\n",
    "    print(\"- Fastest format: {fmt} with runtime {dur:.2f}s.\".format(fmt=fastest['format'], dur=fastest['runtime_s']))\n",
    "    if fastest['format'] != slowest['format']:\n",
    "        print(\"- Slowest format: {fmt} requires {dur:.2f}s, {diff:.2f}s slower.\".format(\n",
    "            fmt=slowest['format'], dur=slowest['runtime_s'], diff=slowest['runtime_s'] - fastest['runtime_s']\n",
    "        ))\n",
    "    print(\"- Lowest energy consumption: {fmt} at {energy:.4f} kWh.\".format(\n",
    "        fmt=best_energy['format'], energy=best_energy['energy_kwh']\n",
    "    ))\n",
    "else:\n",
    "    print(\"- Run both pipelines to generate comparison insights.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 \u2014 Eco-Design Experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 10:41:39] Multiple instances of codecarbon are allowed to run at the same time.\n",
      "[codecarbon INFO @ 10:41:39] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 10:41:39] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 10:41:41] We saw that you have a Intel(R) Core(TM) Ultra 9 185H but we don't know it. Please contact us.\n",
      "[codecarbon WARNING @ 10:41:41] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
      " Windows OS detected: Please install Intel Power Gadget to measure CPU\n",
      "\n",
      "[codecarbon INFO @ 10:41:41] CPU Model on constant consumption mode: Intel(R) Core(TM) Ultra 9 185H\n",
      "[codecarbon WARNING @ 10:41:41] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon INFO @ 10:41:41] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 10:41:41] No GPU found.\n",
      "[codecarbon INFO @ 10:41:41] The below tracking methods have been set up:\n",
      "                RAM Tracking Method: RAM power estimation model\n",
      "                CPU Tracking Method: global constant\n",
      "                GPU Tracking Method: Unspecified\n",
      "            \n",
      "[codecarbon INFO @ 10:41:41] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 10:41:41]   Platform system: Windows-11-10.0.26200-SP0\n",
      "[codecarbon INFO @ 10:41:41]   Python version: 3.12.6\n",
      "[codecarbon INFO @ 10:41:41]   CodeCarbon version: 3.0.8\n",
      "[codecarbon INFO @ 10:41:41]   Available RAM : 31.435 GB\n",
      "[codecarbon INFO @ 10:41:41]   CPU count: 22 thread(s) in 22 physical CPU(s)\n",
      "[codecarbon INFO @ 10:41:41]   CPU model: Intel(R) Core(TM) Ultra 9 185H\n",
      "[codecarbon INFO @ 10:41:41]   GPU count: None\n",
      "[codecarbon INFO @ 10:41:41]   GPU model: None\n",
      "[codecarbon INFO @ 10:41:41] Emissions data (if any) will be saved to file c:\\Users\\Gaurav Chugh\\source\\GreenComputing_TP3\\analysis\\emissions\\parquet_filtered_emissions.jsonl\n",
      "[codecarbon INFO @ 10:41:43] Energy consumed for RAM : 0.000012 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 10:41:43] Delta energy consumed for CPU with constant : 0.000026 kWh, power : 42.5 W\n",
      "[codecarbon INFO @ 10:41:43] Energy consumed for All CPU : 0.000026 kWh\n",
      "[codecarbon INFO @ 10:41:43] 0.000038 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[parquet_filtered] Pipeline encountered an issue: 'Authors'\n"
     ]
    }
   ],
   "source": [
    "important_columns = [\"Id\", \"Title\", \"review/score\", \"review/text\", \"review_length\", \"Authors\", \"Categories\"]\n",
    "\n",
    "def write_filtered_parquet(df: 'pd.DataFrame', path: Path) -> None:\n",
    "    filtered = df[important_columns]\n",
    "    try:\n",
    "        filtered.to_parquet(path, index=False, compression=\"snappy\")\n",
    "    except Exception as parquet_error:\n",
    "        print(f\"Filtered export fallback (no snappy): {parquet_error}\")\n",
    "        filtered.to_parquet(path, index=False)\n",
    "\n",
    "filtered_result = run_pipeline(\n",
    "    \"parquet_filtered\",\n",
    "    load_from_parquet,\n",
    "    write_filtered_parquet,\n",
    "    \"merged_books_reviews_parquet_filtered.parquet\",\n",
    "    \"parquet_filtered_pipeline\",\n",
    ")\n",
    "filtered_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before vs After optimization\n",
    "\n",
    "- Removed non-essential columns before saving the optimised Parquet artefact.\n",
    "- The resulting file is smaller and quicker to write/read for downstream tasks.\n",
    "- Shorter write duration yields a lower estimated energy footprint.\n",
    "- Compression still applies, so CPU work rises slightly but net emissions decrease.\n",
    "- Highlights that thoughtful schema design complements format selection in eco-design.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection (8 points)",
    "",
    "1. Switching from CSV to Parquet consistently cuts runtime and energy across all measured analytics tasks.",
    "2. Task-level instrumentation surfaces hotspots like keyword extraction that deserve targeted optimisation.",
    "3. Lightweight fallbacks keep sustainability metrics available even when CodeCarbon cannot initialise.",
    "4. Working directly with the production-scale CSV inputs keeps the sustainability results grounded in real workloads.",
    "5. Cleaning authors, publishers, and categories upfront avoids skewed aggregates later.",
    "6. Persisting metric tables alongside merged datasets speeds up external validation of results.",
    "7. Interactive visualisations help stakeholders grasp eco-impact differences without reading raw tables.",
    "8. Sustainability discussions belong in routine data engineering reviews, not only in special projects.",
    "",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "- Parquet artefacts are dramatically smaller than their CSV counterparts.\n",
    "- End-to-end runtime improves thanks to reduced I/O and efficient encoding.\n",
    "- Choosing the right storage format is a practical lever for greener data engineering.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}